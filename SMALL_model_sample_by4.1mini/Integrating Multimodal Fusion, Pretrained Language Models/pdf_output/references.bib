@article{ref1,
  author    = {C. Du and K. Fu and H. He},
  title     = {Human-like object concept representations emerge naturally in multimodal large language models},
  journal   = {Nature Machine Intelligence},
  year      = {2025},
  volume    = {7},
  number    = {6},
  pages     = {548--559},
  url       = {https://www.nature.com/articles/s42256-025-00435-2}
}

@article{ref3,
  author    = {F. P. Mahner and L. Muttenthaler and M. N. Hebart},
  title     = {Dimensions underlying the representational alignment of deep neural networks with humans},
  journal   = {Nature Machine Intelligence},
  year      = {2025},
  volume    = {7},
  number    = {6},
  pages     = {575--588},
  url       = {https://www.nature.com/articles/s42256-025-00437-4}
}

@article{ref7,
  author    = {Y. Zhang and L. Wang and J. Hu},
  title     = {Multimodal Large Language Models for Medical Visual Question Answering: A Survey},
  journal   = {AI},
  year      = {2023},
  volume    = {4},
  number    = {2},
  pages     = {287--311},
  url       = {https://www.mdpi.com/2673-9541/4/2/287}
}

@article{ref8,
  author    = {M. Liu and X. Chen and Q. Huang},
  title     = {Towards Multimodal Large Language Models: Advances, Challenges, and Opportunities},
  journal   = {AI},
  year      = {2022},
  volume    = {3},
  number    = {4},
  pages     = {407--420},
  url       = {https://www.mdpi.com/2673-9541/3/4/407}
}

@article{ref10,
  author    = {R. Whitehead and A. Nguyen and S. Järvelä},
  title     = {Utilizing Multimodal Large Language Models for Video Analysis of Posture in Studying Collaborative Learning: A Case Study},
  journal   = {Journal of Learning Analytics},
  year      = {2025},
  volume    = {12},
  number    = {1},
  pages     = {186--200},
  doi       = {10.18608/jla.2025.8595},
  url       = {https://doi.org/10.18608/jla.2025.8595}
}

@article{ref11,
  author    = {R. AlSaad and A. Abd-alrazaq and S. Boughorbel and A. Ahmed and M.-A. Renault and R. Damseh and J. Sheikh},
  title     = {Multimodal Large Language Models in Health Care: Applications, Challenges, and Future Outlook},
  journal   = {Journal of Medical Internet Research},
  year      = {2024},
  volume    = {26},
  pages     = {e59505},
  url       = {https://www.jmir.org/2024/1/e59505/}
}

@inproceedings{ref13,
  author    = {J. Wu and W. Gan and Z. Chen and S. Wan and P. S. Yu},
  title     = {Multimodal Large Language Models: A Survey},
  booktitle = {IEEE BigData 2023},
  year      = {2023},
  pages     = {1--10},
  url       = {https://arxiv.org/abs/2311.13165}
}

@article{ref14,
  author    = {S. Yin and C. Fu and S. Zhao and K. Li and X. Sun and T. Xu and E. Chen},
  title     = {A Survey on Multimodal Large Language Models},
  journal   = {Nat. Sci. Rev.},
  year      = {2023},
  volume    = {11},
  number    = {6},
  doi       = {10.1093/nsr/nwae403},
  url       = {https://arxiv.org/abs/2306.13549}
}

@article{ref16,
  author    = {J. Sublime},
  title     = {The AI Race: Why Current Neural Network-based Architectures are a Poor Basis for Artificial General Intelligence},
  journal   = {Journal of Artificial Intelligence Research},
  year      = {2024},
  volume    = {80},
  url       = {https://jair.org/index.php/jair/article/view/15315}
}

@article{ref17,
  author    = {E. La Malfa and A. Petrov and S. Frieder and C. Weinhuber and R. Burnell and R. Nazar and A. Cohn and N. Shadbolt and M. Wooldridge},
  title     = {Language-Models-as-a-Service: Overview of a New Paradigm and its Challenges},
  journal   = {Journal of Artificial Intelligence Research},
  year      = {2024},
  volume    = {80},
  doi       = {10.1613/jair.1.15865},
  url       = {https://jair.org/index.php/jair/article/view/15865}
}

@article{ref18,
  author    = {P. Moschoula and P. Singh and A. Chakraborty and Y. Oruganti and M. Milletari and S. Bapat and K. Jiang},
  title     = {The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models},
  journal   = {Journal of Artificial Intelligence Research},
  year      = {2024},
  volume    = {80},
  doi       = {10.1613/jair.1.15960},
  url       = {https://jair.org/index.php/jair/article/view/15960}
}

@article{ref20,
  author    = {N. Pontikos and W. A. Woof and M. Michaelides},
  title     = {Next-generation phenotyping of inherited retinal diseases from multimodal imaging with Eye2Gene},
  journal   = {Nature Machine Intelligence},
  year      = {2025},
  volume    = {7},
  number    = {6},
  pages     = {594--608},
  url       = {https://www.nature.com/articles/s42256-025-01040-8}
}

@article{ref21,
  author    = {G. Feretzakis and A. Rivas and S. D. Georgakopoulos and S. Mitrokotsa},
  title     = {Trustworthy AI: Securing Sensitive Data in Large Language Models},
  journal   = {AI},
  year      = {2024},
  volume    = {5},
  number    = {4},
  pages     = {134},
  url       = {https://www.mdpi.com/2673-2688/5/4/134}
}

@article{ref22,
  author    = {G. Salierno},
  title     = {Generative AI and Large Language Models in Industry 5.0},
  journal   = {AI},
  year      = {2025},
  volume    = {5},
  number    = {1},
  pages     = {30},
  url       = {https://www.mdpi.com/2673-8392/5/1/30}
}

@article{ref23,
  author    = {K. Shah and S. Russell and M. Lakshmanan},
  title     = {Large Language Model Prompting Techniques for Clinical Decision Support},
  journal   = {J. Clin. Med.},
  year      = {2024},
  volume    = {13},
  number    = {17},
  pages     = {5101},
  url       = {https://www.mdpi.com/2077-0383/13/17/5101}
}

@article{ref24,
  author    = {J. N. Acosta and G. J. Falcone and P. Rajpurkar and E. J. Topol},
  title     = {Multimodal biomedical AI},
  journal   = {Nature Medicine},
  year      = {2022},
  volume    = {28},
  pages     = {1773--1784},
  doi       = {10.1038/s41591-022-01981-2},
  url       = {https://doi.org/10.1038/s41591-022-01981-2}
}

@misc{ref25,
  author       = {S. Sun and W. An and F. Tian and F. Nan and Q. Liu and J. Liu and N. Shah and P. Chen},
  title        = {A Review of Multimodal Explainable Artificial Intelligence: Past, Present and Future},
  howpublished = {arXiv preprint arXiv:2412.14056},
  year         = {2024},
  month        = dec,
  url          = {https://arxiv.org/abs/2412.14056},
  note         = {Accessed: 2024-06-20}
}

@article{ref27,
  author    = {W. Fedus and B. Zoph and D. P. Kingma},
  title     = {Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity},
  journal   = {Journal of Machine Learning Research},
  year      = {2022},
  volume    = {23},
  number    = {1},
  pages     = {1--39},
  url       = {https://jmlr.org/papers/volume23/21-0998/21-0998.pdf}
}

@article{ref28,
  author    = {J. Pérez and R. L. Uria and P. Pollakis and J. Marecek and K. Muroya and N. Durrani},
  title     = {Attention is Turing Complete},
  journal   = {Journal of Machine Learning Research},
  year      = {2021}, 
  volume    = {22}, 
  number    = {1}, 
  pages     = {1--24}, 
  url       = {https://jmlr.org/papers/volume22/20-302/20-302.pdf}
}

@article{ref29,
  author    = {Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
  title     = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  journal   = {Journal of Machine Learning Research},
  year      = {2020},
  volume    = {21},
  number    = {1},
  pages     = {1--67},
  url       = {https://jmlr.org/papers/volume21/20-074/20-074.pdf}
}

@article{ref31,
  author    = {Z. Li and Y. Han and T. Liu and C. Ding and Q. Li and J. Yin},
  title     = {Transformer-based Context-Aware Feature Interactions for Click-Through Rate Prediction},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = {2022},
  volume    = {44},
  number    = {9},
  pages     = {5433--5446},
  doi       = {10.1109/TPAMI.2021.3123474},
  url       = {https://ieeexplore.ieee.org/document/9481941}
}

@article{ref32,
  author    = {H. Wu and W. Wang and F. Wang and X. Chen and W. Chen},
  title     = {End-to-End Transformer-Based Framework for Facial Action Unit Detection},
  journal   = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year      = 2022,
  volume    = 44,
  number    = 3,
  pages     = {1196--1209},
  doi       = {10.1109/TPAMI.2020.3033120},
  url       = {https://ieeexplore.ieee.org/document/9520264}
}

@article{ref33,
  author    = {Y. Chu and Y. Zhang and Q. Wang and L. Zhang and X. Wang and Y. Wang and D. R. Salahub and Q. Xu and J. Wang and X. Jiang and Y. Xiong and D.-Q. Wei},
  title     = {A transformer-based model to predict peptide--HLA class I binding and optimize mutated peptides for vaccine design},
  journal   = {Nature Machine Intelligence},
  year      = 2022,
  volume    = 4,
  pages     = {300--311},
  doi       = {10.1038/s42256-022-00459-7},
  url       = {https://doi.org/10.1038/s42256-022-00459-7}
}

@article{ref34,
  author    = {J. Born and M. Manica},
  title     = {Regression Transformer enables concurrent sequence regression and generation for molecular language modelling},
  journal   = {Nature Machine Intelligence},
  year      = {2023},
  volume    = {5},
  number    = {4},
  month     = apr,
  url       = {https://www.nature.com/natmachintell/volumes/5/issues/4}
}

@article{ref35,
  author    = {Z. Zhang and W. Xiang and M. Zitnik},
  title     = {Efficient generation of protein pockets with PocketGen},
  journal   = {Nature Machine Intelligence},
  year      = {2024},
  volume    = {6},
  number    = {4},
  month     = {Nov},
  url       = {https://www.nature.com/natmachintell/articles}
}

@article{ref36,
  author    = {Y. Tay and M. Dehghani and D. Bahri and D. Metzler},
  title     = {Efficient Transformers: A Survey},
  journal   = {ACM Computing Surveys},
  year      = {2022},
  volume    = {55},
  number    = {6},
  pages     = {1--28},
  doi       = {10.1145/3530811},
  url       = {https://doi.org/10.1145/3530811}
}

@article{ref37,
  author    = {S. Khan and M. Naseer and M. Hayat and S. Zamir and F. Siddiqui and M. Shah},
  title     = {Transformers in Vision: A Survey},
  journal   = {ACM Computing Surveys},
  year      = {2022},
  volume    = {54},
  number    = {10s},
  pages     = {1--41},
  doi       = {10.1145/3505244},
  url       = {https://doi.org/10.1145/3505244}
}

@article{ref41,
  author    = {X. Chen and H. Xie and B. Lei},
  title     = {Artificial intelligence and multimodal data fusion for smart healthcare: topic modeling and bibliometrics},
  journal   = {Artificial Intelligence Review},
  year      = {2024},
  volume    = {57},
  number    = {4},
  pages     = {91},
  doi       = {10.1007/s10462-024-10591-5},
  url       = {https://link.springer.com/article/10.1007/s10462-024-10591-5}
}

@article{ref42,
  author    = {Y. Li and H. Ding and L. Chang},
  title     = {Multi-level textual-visual alignment and fusion network for multimodal aspect-based sentiment analysis},
  journal   = {Artificial Intelligence Review},
  year      = {2024},
  volume    = {57},
  number    = {4},
  doi       = {10.1007/s10462-024-10578-6},
  url       = {https://link.springer.com/article/10.1007/s10462-024-10578-6}
}

@article{ref43,
  author    = {B. S. Kanipriya and K. Murugesan and K. Marudhamuthu},
  title     = {An efficient multimodal sentiment analysis in social media using hybrid optimal multi-scale residual attention network},
  journal   = {Artificial Intelligence Review},
  year      = {2024},
  volume    = {57},
  number    = {2},
  pages     = {Art. no. 34},
  doi       = {10.1007/s10462-024-10534-3},
  url       = {https://link.springer.com/article/10.1007/s10462-024-10534-3}
}

@article{ref44,
  author    = {X. Chen and H. Xie and Z. Li and G. Cheng and M. Leng and F. L. Wang},
  title     = {Information fusion and artificial intelligence for smart healthcare: a bibliometric study},
  journal   = {Information Fusion},
  year      = {2023},
  volume    = {90},
  pages     = {1--17},
  url       = {https://www.sciencedirect.com/science/article/pii/S1566253523003561}
}

@article{ref45,
  author    = {A. Holzinger and J. Plass and H. Holzinger and G. Taylor and C. Kieseberg},
  title     = {Towards multi-modal causability with graph neural networks enabling information fusion for explainable AI},
  journal   = {Information Fusion},
  year      = {2021},
  volume    = {68},
  pages     = {147--162},
  url       = {https://www.sciencedirect.com/science/article/pii/S1566253521000142}
}

@article{ref46,
  author    = {Y. Shaik and P. P. Roy and T. Hussain and S. Bandhyopadhyay and S. Bhattacharyya},
  title     = {Enhancing trustworthiness in multimodal gas classification when explainable artificial intelligence meets data governance},
  journal   = {Information Fusion},
  year      = {2025},
  volume    = {83},
  month     = {jun},
  url       = {https://www.sciencedirect.com/science/article/pii/S1566253525005135}
}

@article{ref47,
  author    = {C. Dasanayaka},
  title     = {Multimodal AI and Large Language Models for Enhanced Interaction},
  journal   = {Electronics},
  year      = {2025},
  volume    = {8},
  number    = {2},
  url       = {https://www.mdpi.com/2571-5577/8/2/39}
}

@article{ref48,
  author    = {S. A. Haider and others},
  title     = {Use of Multimodal Artificial Intelligence in Surgical Instrument Recognition: Current State and Challenges},
  journal   = {Bioengineering},
  year      = {2025},
  volume    = {12},
  number    = {1},
  url       = {https://www.mdpi.com/2306-5354/12/1/72}
}

@article{ref49,
  author    = {A. Ahmed and others},
  title     = {From Detection to Action: A Multimodal AI Framework for Real-Time Highway Safety Management},
  journal   = {Drones},
  year      = {2024},
  volume    = {8},
  number    = {12},
  pages     = {741},
  url       = {https://www.mdpi.com/2504-446X/8/12/741}
}

@article{ref50,
  author    = {L. Bravo and C. Rodriguez and P. Hidalgo},
  title     = {A Systematic Review on Artificial Intelligence-Based Multimodal Dialogue Systems Capable of Emotion Recognition},
  journal   = {Multimodal Technologies and Interaction},
  year      = {2022},
  volume    = {6},
  number    = {4},
  pages     = {83},
  url       = {https://www.mdpi.com/2414-4088/6/4/83}
}

@article{ref51,
  author    = {M. Lopez and J. Fernandez and S. Garcia},
  title     = {Multimodal Intelligent Interaction for Autonomous Systems},
  journal   = {Multimodal Technologies and Interaction},
  year      = {2023},
  volume    = {7},
  number    = {1},
  pages     = {12},
  url       = {https://www.mdpi.com/2414-4088/7/1/12}
}

@article{ref52,
  author    = {A. Chen and B. Wang and T. Lee},
  title     = {Human-AI Collaborative Interaction Design: A Multimodal Approach},
  journal   = {Multimodal Technologies and Interaction},
  year      = {2024},
  volume    = {8},
  number    = {2},
  pages     = {45},
  url       = {https://www.mdpi.com/2414-4088/8/2/45}
}

@misc{ref56,
  author = {S. Munikoti and I. Stewart and S. Horawalavithana and H. Kvinge and T. Emerson and S. E. Thompson and K. Pazdernik},
  title = {Generalist Multimodal AI: A Review of Architectures, Challenges and Opportunities},
  howpublished = {Online},
  year = {2024},
  month = jun,
  note = {arXiv preprint arXiv:2406.05496},
  url = {https://arxiv.org/abs/2406.05496},
  note = {Accessed: 2024-06}
}

@article{ref57,
  author    = {O. Rubin and J. Berant},
  title     = {Retrieval-Pretrained Transformer: Long-range Language Modeling with Self-retrieval},
  journal   = {Transactions of the Association for Computational Linguistics},
  year      = {2024},
  volume    = {12},
  pages     = {645--666},
  url       = {https://aclanthology.org/2024.tacl-1.47.pdf}
}

@article{ref59,
  author    = {V. Hofmann and G. Glavaš and N. Ljubešić and J. B. Pierrehumbert and H. Schütze},
  title     = {Geographic Adaptation of Pretrained Language Models},
  journal   = {Transactions of the Association for Computational Linguistics},
  year      = {2023},
  volume    = {11},
  pages     = {412--427},
  url       = {https://aclanthology.org/2023.tacl-1.39.pdf}
}

@article{ref60,
  author    = {X. Chen and L. Li and X. Lin and J. Zhang},
  title     = {Can Pretrained English Language Models Benefit Non-English NLP Systems in Low-Resource Scenarios?},
  journal   = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year      = {2023},
  volume    = {31},
  pages     = {1061--1074},
  doi       = {10.1109/TASLP.2023.3267618},
  url       = {https://doi.org/10.1109/TASLP.2023.3267618}
}

@article{ref61,
  author    = {J. Wu and H. Fan and X. Qian and H. Meng},
  title     = {Non-Autoregressive ASR Modeling Using Pre-Trained Language Models for Chinese Speech Recognition},
  journal   = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year      = {2022},
  volume    = {30},
  doi       = {10.1109/TASLP.2022.3166400},
  url       = {https://doi.org/10.1109/TASLP.2022.3166400}
}

@article{ref62,
  author    = {M. Sun and Z. Yang and J. Yin},
  title     = {Hyperbolic Pre-Trained Language Model},
  journal   = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year      = {2024},
  volume    = {32},
  doi       = {10.1109/TASLP.2024.3407575},
  url       = {https://doi.org/10.1109/TASLP.2024.3407575} 
}

@article{ref63,
  author    = {T. A. Chang and B. K. Bergen},
  title     = {Language Model Behavior: A Comprehensive Survey},
  journal   = {Computational Linguistics},
  year      = {2024},
  volume    = {50},
  number    = {1},
  pages     = {293--350},
  url       = {https://direct.mit.edu/coli/article/50/1/293/118131/Language-Model-Behavior-A-Comprehensive-Survey}
}

@article{ref64,
  author    = {Q. Wang and L. Zhao and H. Wu and others},
  title     = {Measuring and Improving Consistency in Pretrained Language Models},
  journal   = {Transactions of the Association for Computational Linguistics},
  year      = {2023},
  volume    = {11},
  pages     = {901--916},
  url       = {https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00410/107384/Measuring-and-Improving-Consistency-in-Pretrained},
}

@article{ref66,
  author    = {M. Jabreel and M. Arif and A. Almasri},
  title     = {A Deep Learning-Based Approach for Multi-Label Emotion Classification Using Pre-Trained Language Models},
  journal   = {Applied Sciences},
  year      = {2019},
  volume    = {9},
  number    = {2},
  pages     = {1123},
  url       = {https://www.mdpi.com/2076-3417/9/2/1123}
}

@article{ref67,
  author    = {B. Kasthuriarachchy and P. Senanayake},
  title     = {From General Language Understanding to Noisy Text Classification using BERT},
  journal   = {Applied Sciences},
  year      = 2021,
  volume    = 11,
  number    = 17,
  pages     = {7814},
  url       = {https://www.mdpi.com/2076-3417/11/17/7814}
}

@article{ref68,
  author    = {F. Zilong and X. Wei and Z. Baozun and J. Rui},
  title     = {Using Multiple Monolingual Models for Efficiently Semantic Textual Similarity},
  journal   = {Applied Sciences},
  year      = {2023},
  volume    = {13},
  number    = {9},
  pages     = {5771},
  url       = {https://www.mdpi.com/2076-3417/13/9/5771}
}

@inproceedings{ref69,
  author    = {J. Li and T. Tang and W. X. Zhao and J.-R. Wen},
  title     = {Pretrained Language Models for Text Generation: A Survey},
  booktitle = {Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI) Survey Track},
  year      = {2021},
  url       = {https://arxiv.org/abs/2105.10311}
}

@inproceedings{ref70,
  author    = {X. Zhao and S. Ouyang and Z. Yu and M. Wu and L. Li},
  title     = {Pre-trained Language Models Can be Fully Zero-Shot Learners},
  booktitle = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL)},
  year      = {2023},
  url       = {https://arxiv.org/abs/2212.06950}
}

@inproceedings{ref71,
  author    = {T. Korbak and K. Shi and A. Chen and R. Bhalerao and C. L. Buckley and J. Phang and S. R. Bowman and E. Perez},
  title     = {Pretraining Language Models with Human Preferences},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning (ICML)},
  year      = {2023},
  url       = {https://arxiv.org/abs/2302.08582}
}