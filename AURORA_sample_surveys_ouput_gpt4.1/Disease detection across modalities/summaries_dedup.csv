Index,Citation,Summary
1,"O. Vandenberg, D. Martiny, O. Rochas, A. van Belkum, and Z. Kozlakidis, ""Considerations for diagnostic COVID-19 tests,"" Nature Reviews Microbiology, vol. 19, pp. 171–183, 2021. Available: https://www.nature.com/articles/s41579-020-00461-z","This review summarizes the urgent and large-scale development, validation, and implementation of diagnostic tests, primarily molecular assays such as RT-PCR and immunoassays, during the first global wave of the COVID-19 pandemic. The paper details two main approachesdirect detection of viral nucleic acids/proteins and immunological detection of host responsewhile highlighting rapid advances and practical challenges, such as test sensitivity, specificity, supply chain vulnerabilities, standardization issues, and difficulties particularly pronounced in low-resource settings. By September 2020, over 240 diagnostic tests had received emergency use authorization, though many still lack comprehensive clinical validation and formal regulatory approval. The discussion points to logistical, regulatory, and ethical challenges, the need for continual quality control, and the importance of integrating diagnostics into broader clinical and public health frameworks supported by digital and AI solutions. The review advocates for future efforts in assay optimization, robust validation, more equitable global test access, and the intertwining of diagnostic strategies with community compliance and infection control for optimal pandemic response. Ultimately, diagnostics are valuable not in isolation but when they drive therapy choices, follow-up, and community-level intervention, underlining the necessity of global solidarity and coordinated preparedness for future pandemics."
2,"I. N. Okeke and C. Ihekweazu, ""The importance of molecular diagnostics for infectious diseases in low-resource settings,"" Nature Reviews Microbiology, vol. 19, pp. 547–548, 2021. Available: https://www.nature.com/articles/s41579-021-00598-5","Molecular diagnostics, characterized by their agility, speed, and flexibility, present an effective solution for infectious disease detection in resource-limited settings where the spectrum of potential pathogens is wide. Traditionally, these methods were deemed unsustainable due to their perceived complexity and high cost. However, challenges with sustaining culture-based microbiology and the limitations of serological methods in these environments underscore a critical need for efficient molecular approaches. The COVID-19 pandemic in Nigeria, where public health laboratories equipped for SARS-CoV-2 molecular testing increased from four to 72 within a year through coordinated efforts, training, and pooled procurement, serves as proof-of-concept for scalability even amid resource constraints. Further, molecular methods have demonstrated superiority over conventional diagnostics in outbreak detection (e.g., Ebola, Yellow fever) and have revealed hidden epidemics, as shown by increased sensitivity in meningitis surveillance in Bangladesh. Despite the risk of contamination and the technical requirements of PCR, innovations like microfluidics, miniaturization, and accessible systems (e.g., Gene Xpert, Oxford nanopore sequencers) are mitigating barriers. Molecular diagnostics will complement rather than replace culture, extending access to millions and improving surveillance in hard-to-reach populations, as exemplified by the successful mapping of typhoid hotspots using DNA detection. For sustainable integration, robust supply chains, infrastructure improvements (like solar backups and smart devices), and adaptive governance by public health institutes are essential. Going forward, fitting molecular technologies to local realities and challenges can transform infectious disease diagnostics in low-resource settings."
3,"R. E. Baker, A. S. Mahmud, I. F. Miller, M. Rajeev, F. Rasambainarivo, B. L. Rice, S. Takahashi, A. J. Tatem, C. E. Wagner, L.-F. Wang, A. Wesolowski, and C. J. E. Metcalf, ""Infectious disease in an era of global change,"" Nature Reviews Microbiology, vol. 20, pp. 193–205, 2022. Available: https://www.nature.com/articles/s41579-021-00639-z","The abstract discusses how the twenty-first century has been marked by multiple major infectious disease outbreaks, including the COVID-19 pandemic, SARS in 2003, the 2009 swine flu, the 2012 MERS outbreak, the 20132016 Ebola epidemic, and the 2015 Zika virus outbreakeach causing significant morbidity, mortality, and international spread. In parallel, global shifts such as a doubling of airline flights since 2000, urbanization surpassing rural living since 2007, ongoing population growth, and escalating climate change have all potentially heightened the risk of infectious disease emergence and dissemination. Despite these new risks, improvements in sanitation and healthcare access have led to noteworthy health progress globally. The Review aims to evaluate how these transformative global changes may be influencing the risk and profile of infectious disease outbreaks."
4,"T. Weitzel, C. Pérez, D. Tapia, P. Legarraga, and L. Porte, ""SARS-CoV-2 rapid antigen detection tests,"" The Lancet Infectious Diseases, vol. 21, no. 8, pp. 1067–1068, Aug. 2021. [Online]. Available: https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(21)00249-8/fulltext DOI: 10.1016/S1473-3099(21)00249-8","In response to concerns over the imperfect specificity of SARS-CoV-2 antigen rapid detection tests (Ag-RDTs) in low-prevalence, asymptomatic populations, the authors evaluated an automated fluorescence immunoassay (STANDARD F COVID-19 Ag) in 773 asymptomatic preoperative or pre-childbirth individuals, with all testing negative by RT-PCR but 67 (8.7%) initially testing positive by Ag-RDT. Repeating Ag-RDTs on positive samples lowered false positives to 42 (5.5%), and increasing the cutoff for positivity from 1.0 to 3.0, based on a ROC curve (optimal cutoff at 3.36 for 100% sensitivity and 98.5% specificity), reduced false positives to 17 (2.2%). Combining both strategies resulted in only 6 false positives and a specificity of 99.2%. The results, summarized in the following table:

\[
\begin{tabular}{|l|c|c|c|c|}
\hline
\text{Cutoff/Strategy} & \text{Total} & \text{True Negatives} & \text{False Positives} & \text{Specificity} \\
\hline
\geq 1.0\, (\text{manufacturer}) & 773 & 706 & 67 & 91.3\% \\
\text{Positive twice} (\geq 1.0) & 767 & 725 & 42 & 94.5\% \\
\geq 3.0 & 773 & 756 & 17 & 97.8\% \\
\text{Positive twice,\ } \geq 3.0 & 767 & 761 & 6 & 99.2\% \\
\hline
\end{tabular}
\]

demonstrate that optimizing testing protocols by repeating tests and using higher cutoff levels can significantly improve the specificity of Ag-RDTs without sacrificing rapid turnaround, thereby enhancing practicality and acceptance for mass screening of asymptomatic individuals. Further studies are warranted to confirm these findings."
5,"M. V. Kiang, E. T. Chin, B. Q. Huynh, L. A. C. Chapman, I. Rodríguez-Barraquer, B. Greenhouse, G. W. Rutherford, K. Bibbins-Domingo, D. Havlir, S. Basu, and N. C. Lo, ""Routine asymptomatic testing strategies for airline travel during the COVID-19 pandemic: a simulation study,"" The Lancet Infectious Diseases, vol. 21, no. 7, pp. 929–938, July 2021. [Online]. Available: https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(21)00134-1/fulltext DOI: 10.1016/S1473-3099(21)00134-1","This study used a microsimulation model of 100,000 airline travelers to evaluate the effectiveness of five SARS-CoV-2 asymptomatic testing strategiespre- and post-travel PCR tests and rapid antigen testson reducing both individual risk of COVID-19 infection during air travel and population-level transmission after travel. Results indicated that a pre-travel PCR test within three days before departure reduced infectious days by 35% and identified 88% of infectious travelers on the day of flight, while pairing pre-travel and post-arrival PCR with a short quarantine led to a 79% reduction in infectious days. Similarly, a rapid antigen test on the day of travel reduced infectious days by 32% and, when combined with post-arrival PCR and quarantine, achieved a 70% reduction. Post-arrival PCR testing alone reduced infectious days by 42%. However, all strategies presented trade-offs involving test sensitivity, specificity, and the potential for false positives, especially given low community prevalence and imperfect test characteristics (e.g., specificity $=99.8\%$). Additional limitations include assumptions of perfect compliance and resource needs for widespread implementation. Ultimately, the findings support routine asymptomatic testing in conjunction with masking and distancing to help mitigate COVID-19 risk from air travel, though no approach guarantees absolute prevention; national policy should weigh each strategy's strengths and drawbacks along with ongoing non-pharmaceutical interventions."
6,"L. M. R. Kasbergen, E. de Bruin, F. Chandler, A. J. Menting, P. A. M. Kouwijzer, L. Schwanitz, V. Klaus, K. H. Adan, S. Markota, R. G. P. Alblas, et al., ""Multi-antigen serology and a diagnostic algorithm for the detection of arbovirus infections as novel tools for arbovirus preparedness in southeast Europe: a prospective observational study,"" The Lancet Infectious Diseases, vol. 24, no. 6, pp. 689–698, June 2024. [Online]. Available: https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(24)00654-6/fulltext DOI: 10.1016/S1473-3099(24)00654-6","Arboviruses are increasingly impacting Europe, necessitating improved surveillance and diagnostics due to overlapping clinical syndromes and climate-driven spread. This study analyzed data from 863 adults hospitalized with arboviral-like syndromes in southeast Europe, collected across 21 hospitals over four arbovirus seasons (201619), focusing on four endemic arboviruses: Crimean-Congo haemorrhagic fever virus (CCHFV), tick-borne encephalitis virus (TBEV), Toscana virus, and West Nile virus (WNV). A diagnostic algorithm was developed to account for challenges in serology and variable sample timing, using ELISAs, immunofluorescence, custom protein microarrays, and PCR testing on samples at multiple timepoints. Findings revealed confirmed recent infections in one patient with CCHFV (<1%), 10 with TBEV (1%), 40 with Toscana virus (5%), and 52 with WNV (6%). Notable geographical clustering included Toscana virus in Albania (63% of cases) and WNV in Romania (69%). Toscana virus seropositivity was high in Albania (60%), and antibody presence correlated with older age. Risk factors included male sex for Toscana virus (odds ratio 1.56, 95% CI 1.152.11; $p=0.0055$), mosquito bites for WNV (odds ratio 2.47, 95% CI 1.543.97; $p=0.0002$), and tick bites for TBEV (odds ratio 2.21, 95% CI 1.194.11; $p=0.018$). Despite incomplete data, the diagnostic algorithm facilitated differential diagnosis, suggesting its utility for clinical diagnostics and strengthening arbovirus surveillance, while highlighting regional hotspots and risk associations."
7,"A. J. Sundermann, J. Chen, P. Kumar, A. M. Ayres, S. T. Cho, C. Ezeonwuka, M. P. Griffith, J. K. Miller, M. M. Mustapha, A. W. Pasculle, M. I. Saul, K. A. Shutt, V. Srinivasa, K. Waggle, D. J. Snyder, V. S. Cooper, D. Van Tyne, G. M. Snyder, J. W. Marsh, A. Dubrawski, M. S. Roberts, and L. H. Harrison, ""Whole-Genome Sequencing Surveillance and Machine Learning of the Electronic Health Record for Enhanced Healthcare Outbreak Detection,"" Clinical Infectious Diseases, vol. 75, no. 3, pp. 476-482, 2022, doi: 10.1093/cid/ciab946. Available: https://pubmed.ncbi.nlm.nih.gov/34791136/","This study presents the Enhanced Detection System for Healthcare-Associated Transmission (EDS-HAT), integrating whole-genome sequencing (WGS) surveillance and electronic health record (EHR) machine learning (ML) to improve hospital outbreak detection and route identification over traditional infection prevention (IP) methods. Conducted at a large tertiary hospital, WGS was performed on clinical isolates collected over two years, and ML analyzed EHR data to identify statistically significant transmission routes, which were then expertly reviewed. Among 3165 isolates (2752 unique patients), EDS-HAT found 99 clusters (10.8%), identifying routes for 65.7% of clusters, including outbreaks in interventional radiology (VRE, OR: 43.8, $P<.01$), gastroscopy (Pseudomonas, OR: 300.6, $P<.01$), chronic care and ICU units, wound care, and EEG procedures. In parallel, traditional IP prompted WGS in 15 suspected outbreaks (133 patients) but only two clusters matched genetically. Clinical and economic modeling indicated EDS-HAT could prevent 2563 transmissions, 3.18.0 readmissions, and 1.63.3 deaths, achieving cost savings of \$192,408\$692,532 (\$7,745\$10,939 per transmission averted). Challenges included retrospective limitations, possible uncaptured outbreaks, and real-time model effects. The findings endorse EDS-HAT as a cost-saving, effective, and complementary tool for outbreak detection and transmission route analysis, leveraging advances in genomics and ML for enhanced hospital infection surveillance."
8,"A. J. Sundermann, P. Kumar, M. P. Griffith, K. D. Waggle, V. Rangachar Srinivasa, N. Raabe, E. G. Mills, H. Coyle, D. Ereifej, H. M. Creager, A. Ayres, D. Van Tyne, L. L. Pless, G. M. Snyder, M. Roberts, and L. H. Harrison, ""Real-Time Genomic Surveillance for Enhanced Healthcare Outbreak Detection and Control: Clinical and Economic Impact,"" Clinical Infectious Diseases, Apr. 30, 2025:ciaf216. doi: 10.1093/cid/ciaf216. [Online ahead of print] Available: https://pubmed.ncbi.nlm.nih.gov/40302215/","This study evaluated the Enhanced Detection System for Healthcare-associated Transmission (EDS-HAT), a real-time genomic surveillance program for outbreak detection and mitigation in a large tertiary care hospital. Over a two-year period, 3,921 healthcare-associated bacterial isolates underwent whole genome sequencing (WGS), resulting in the identification of 172 outbreaks involving 476 isolates (12.1%), with 61.3% epidemiologically linked. Interventions based on these findings were highly effective: in 95.6% of outbreaks with targeted interventions, transmission along the intervened route ceased. The economic and clinical impact analysis estimated 62 infections averted, yielding gross cost savings of \$1,011,146 and net savings of \$695,706a 3.2-fold return on investment, with probabilistic sensitivity analysis confirming cost savings in 98% of simulations. The methods included twice-weekly isolate collection, rigorous WGS processing and SNP analysis ($\leq 15$ pairwise cgSNPs for most species, $\leq 2$ for C. difficile), and detailed outbreak tracking for targeted infection prevention and control (IP&C) interventions. Challenges included limited pathogen scope, non-inclusion of colonization-only cases, and about a third of outbreaks lacking clear epidemiological linksoften associated with higher genetic distances, indicating that SNP cutoffs could be more stringent. The study concludes that real-time genomic surveillance is a feasible and effective IP&C tool, offering substantial improvements in outbreak detection, patient safety, and cost savings, and recommends broader implementation and national scale-up akin to CDCs PulseNet for foodborne pathogens. Illumina sequencing data are available at NCBI BioProject PRJNA475751."
9,"B. R. Jackson, C. Tarr, E. Strain, K. A. Jackson, A. Conrad, H. Carleton, L. S. Katz, S. Stroika, L. H. Gould, R. K. Mody, B. J. Silk, J. Beal, Y. Chen, R. Timme, M. Doyle, A. Fields, M. Wise, G. Tillman, S. Defibaugh-Chavez, Z. Kucerova, A. Sabol, K. Roache, E. Trees, M. Simmons, J. Wasilenko, K. Kubota, H. Pouseele, W. Klimke, J. Besser, E. Brown, M. Allard, and P. Gerner-Smidt, ""Implementation of Nationwide Real-time Whole-genome Sequencing to Enhance Listeriosis Outbreak Detection and Investigation,"" Clinical Infectious Diseases, vol. 63, no. 3, pp. 380-386, Aug. 1, 2016, doi: 10.1093/cid/ciw242. Available: https://pubmed.ncbi.nlm.nih.gov/27090985/","Listeria monocytogenes (Lm) is a major cause of severe foodborne illness, with high mortality rates and significant economic impact. Traditional molecular subtyping via pulsed-field gel electrophoresis (PFGE) enhanced outbreak detection but suffers from limited genetic resolution and potential for misclassification. In 2013, US agencies began real-time, nationwide whole-genome sequencing (WGS) of all Lm isolates from clinical, food, and environmental sources, publicly posting sequence data, which significantly increased outbreak cluster detection and resolution (pre-WGS: 2 outbreaks/year; post-WGS year 1: 5; year 2: 9). Methods included the adoption of whole-genome multilocus sequence typing (wgMLST) with up to 4804 loci and high-quality single nucleotide polymorphism (hqSNP) analysis, allowing robust phylogenetic inferenceeven by non-specialists. Results show WGS improved outbreak surveillance by delineating clusters with diverse PFGE patterns, refining outbreak definitions, linking sporadic cases to foods, solving cold cases, and confirming outbreaks via product testing; clusters detected increased from 14 (pre-WGS) to 21 (WGS year 2) and median cluster size decreased. Investigations revealed small production environments generated less genetic diversity (1213 allele differences), while larger producers saw more (up to 43). Neither a strict allele nor SNP cutoff reliably defines outbreaks, and epidemiologic context remains essential. WGSs high discriminatory power has strengthened investigations, allowed earlier regulatory interventions, and increased insights into Lm ecology, complementing US preventative food safety measures; success has prompted WGS expansion to other pathogens. Future work focuses on democratizing WGS tools, ensuring standardization, and broadening education for public health interpretation. Challenges remain in interpreting WGS for polyclonal or data-limited situations. For further details see cited references and tables in the original publication."
10,"X. Yang and J. Li, ""Learn from the SARS-CoV-2 nucleic acid test to increase the experience of dealing with the 'disease X,'"" BMC Infectious Diseases, vol. 25, Article no. 593, 2025. [Online]. Available: https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-025-10991-7","This study investigates the relationship between RT-PCR cycle threshold (Ct) values and false positive rates in COVID-19 testing, drawing on data from 1,255 positive or suspected samples across eleven laboratories and seven reagents. When both target genes had Ct < 30, false positive rates were very low (1.72%), but rose sharply with higher Ct values: for any target Ct > 35, 15.5824.22% were false positives, and over half (53.23%) of suspected positive pooled samples proved false upon individual retesting. The findings indicate strong positives (Ct < 30) can be directly reported, while weaker positives and suspected cases (especially Ct > 30 or pooled samples) warrant retesting to avoid unnecessary isolation or misdiagnosis. There were significant differences in false positive rates based on reagent and institution, reflecting the need for standardized cutoffs and context-specific protocols. The study concludes that targeted retesting strategies informed by Ct values optimize accuracy and resource use in large-scale screening, with major implications for managing future outbreaks of newly emerging pathogens (Disease X)."
11,"G. M. Setegn and B. E. Dejene, ""Explainable AI for Symptom-Based Detection of Monkeypox: a machine learning approach,"" BMC Infectious Diseases, vol. 25, Article no. 419, 2025. [Online]. Available: https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-025-10738-4","This study addresses the rising global health threat of monkeypox by proposing a machine learning-based, symptom-driven diagnostic framework enhanced with explainable artificial intelligence (XAI) techniques. Using an open-source clinical dataset (expanded via SMOTE to address class imbalance), the authors implemented and compared several algorithmsincluding Random Forest, Gradient Boosting, CatBoost, XGBoost, and particularly LGBMClassifier, which achieved the best accuracy of 89.3%. Key clinical features such as fever, oral/genital ulcers, swollen lymph nodes, and fatigue were identified as the most influential predictors through XAI tools (SHAP, LIME, ELI5, Counterfactuals, Qlattice), resulting in a transparent, interpretable model. The study deployed the model through a user-friendly Flask web interface to allow real-time, symptom-based prediction of monkeypox risk, thereby bridging advanced AI with practical clinical applications. The approach outperformed image-based systems in interpretability, addressed transparency crucial for healthcare adoption, and has the potential to expedite surveillance, resource allocation, and outbreak response. While limitations include small dataset size and need for larger, more diverse data, the research highlights the practical advantages of XAI in improving diagnostic accuracy, fostering trust among clinicians, and supporting public health management. The authors argue that the integration of their explainable AI tool into healthcare workflows and information systems, with continuous feedback and adaptation, could significantly enhance early detection and control of monkeypox outbreaks."
12,"A. Pierangeli, O. Turriziani, M. Fracella, R. Campagna, F. Frasca, A. D’Auria, C. Scagnolari, P. Roberto, L. Cinti, G. D’Ettorre, G. Ceccarelli, L. Petrarca, R. Nenna, F. Midulla, G. Galardo and G. Antonelli, ""The added value of diagnostics to characterize age-specific patterns of respiratory viral infections and coinfections and to detect emerging threats,"" BMC Infectious Diseases, vol. 25, Article no. 404, 2025. [Online]. Available: https://bmcinfectdis.biomedcentral.com/articles/10.1186/s12879-025-10693-0","This study investigated the circulation of respiratory viruses in children and adults at Sapienza University Hospital during the 2023/24 epidemic season, following disruptions caused by pandemic restrictions. Molecular testing of 1121 patients with acute respiratory infections (ARIs) from October 2023 to June 2024 revealed that 78% were positive for respiratory viruses, predominantly rhinovirus (HRV, 32.4%), influenza A (IAV, 29.2%), and respiratory syncytial virus (RSV, 28.3%). Age-specific patterns emerged, with RSV more common in infants, IAV in adults, and HRV in children aged 15 years. Although IAV, RSV, and HRV cocirculated in winter, HRV also peaked in spring, coinciding with influenza B (IBV) and other viruses. Coinfection analysis showed that pairs like IAV/RSV had significantly fewer observed coinfections than expected by chance (e.g., $p < 0.0001$), suggesting viral interference, particularly between IAV, IBV, and RSV. Sequencing in late spring identified diverse HRV genotypes and rare enterovirus (EV-C105) cases. The findings highlight the return to typical seasonality for respiratory viruses post-pandemic, the impact of viral interference on coinfection rates, and the need for integrated molecular diagnostics and surveillance to characterize viral circulation and promptly detect emerging pandemic threats. Limitations include the studys seasonally restricted period and absence of clinical data, while future work calls for extended surveillance and alignment with WHO recommendations for integrated approaches."
13,"N. Bürgisser, E. Chalot, S. Mehouachi, C. P. Buclin, K. Lauper, D. S. Courvoisier, and D. Mongin, “Large language models for accurate disease detection in electronic health records,” medRxiv, 2024. [Online]. Available: https://www.medrxiv.org/content/10.1101/2024.07.27.24311106v1","This study evaluates the effectiveness of large language models (LLMs), specifically Metas Llama 3 8B, in detecting disease diagnoses from unstructured French-language electronic health records (EHR), using gout and calcium pyrophosphate deposition disease (CPPD) as case examples. The proposed LLM-based framework was tested on 700 manually reviewed and labeled gout-related paragraphs, with performance compared to traditional regular expression (regex) techniques. The LLM achieved superior metrics: positive predictive value of 92.7% [88.795.4%], negative predictive value of 96.6% [94.697.8%], and overall accuracy of 95.4% [93.696.7%]. For CPPD detection on a validation set of 600 paragraphs, accuracy remained high at 94.1% [90.297.6%]. The method was robust across various model parameters and prompt structures. These findings demonstrate that LLMs can accurately and efficiently identify disease mentions in EHRs across languages, potentially streamlining the creation of large patient registries, disease care assessment, and clinical trial recruitment."
14,"A. Matov, “Urinary Biomarkers for Disease Detection,” medRxiv, 2024. [Online]. Available: https://www.medrxiv.org/content/10.1101/2024.07.30.24311186v1","The current healthcare system typically employs a passive model for disease detection, where diagnosis follows symptom-driven patient presentation; this approach often results in late detection of degenerative diseases, by which time cellular damage may be irreversible. Organ-specific nucleic acids, such as panels of microRNAs (miRNAs), play critical roles in tissue function, and monitoring their dynamic abundance offers an avenue for real-time health surveillance. Next-generation sequencing (NGS) technologies now make this proactive monitoring feasible, yet extracting meaningful, early-warning signals from large longitudinal datasets necessitates advanced computational strategies. This study presents preliminary results analyzing healthy donors and untreated lung cancer patients, supporting the potential of miRNA-based NGS in early disease detection and the importance of robust data analytics in harnessing these biomarkers."
15,"N. Krasnow, K. Maurer, C. Song, J. Rhoades, K. Xiong, A. Crnjac, T. Blewett, L. Gao, H. Jacene, R. Merryman, S. H. Gohil, C. Duffy, L. I. Guerrero, J. Dela Cruz, M. McDonough, J. O. Wolff, R. Redd, M. Mattie, B. Miles, G. M. Makrigiorgos, D. S. Neuberg, S. J. Rodig, P. Armand, C. Jacobson, V. A. Adalsteinsson, and C. J. Wu, “Early Measurable Residual Disease Detection after CAR-T is Associated with Poor Outcome Large B-cell Lymphoma Patients,” medRxiv, 2024. [Online]. Available: https://www.medrxiv.org/content/10.1101/2024.11.27.24318095v1","Despite responses of chimeric antigen receptor (CAR)-T cells in relapsed/refractory large B cell lymphoma (LBCL), more than half of patients relapse, necessitating early detection methods for high-risk cases. The authors applied the ultrasensitive, tumor-informed MAESTRO assaycapable of detecting circulating tumor DNA (ctDNA) at parts-per-million (ppm) levels using minimal sequencingto 140 samples from 28 patients treated with axicabtagene ciloleucel (axi-cel). Both responders (n=15) and nonresponders (n=13) had similar baseline tumor burden. By one week post-infusion, responders exhibited a marked reduction in ctDNA relative to nonresponders ($p<0.001$). At weeks 2 and 4, ctDNA in responders approached 0 ppm, while nonresponders showed persistent ctDNA (each $p<0.001$). Notably, 21% of patients at day 0 had ctDNA fractions below 0.01%levels undetectable by less sensitive assays. The findings demonstrate that highly sensitive MRD detection by ctDNA can facilitate early identification of LBCL patients at risk of disease progression following CAR-T therapy."
16,"D. van Kampen and J. Wildfeuer, ""Cohesion in physical movie releases: developing a framework for the multimodal analysis of complex three-dimensional packaging,"" Multimodality & Society, 2024. [Online]. Available: https://doi.org/10.1177/26349795241306993","Three-dimensional packages function as complex, multimodal ensembles with significant communicative roles for constructing marketing strategies and conveying cultural values through the products they encase. This article explores the application of multimodal cohesion analysispreviously applied mostly to narrative forms like films or comicsto these physical artefacts, specifically focusing on physical movie releases. The authors propose a five-step framework tailored for analyzing three-dimensional packaging and test it using three case studies from the film distributor Eureka. The analysis finds that the dominant relation among the packaging elements is repetition, evident through both verbal and visual cues in style and content. Repetitive style fosters strong uniformity across the package, while repetitive content enables effective information transmission, compensating for the nonlinear, three-dimensional structure of these objects."
17,"F. Byrne, ""A diffractive approach to multimodal transcription: Materialising entanglements between humans and non-humans,"" Multimodality & Society, 2024. [Online]. Available: https://doi.org/10.1177/26349795241291369","This paper explores the alignment between multimodality and posthumanism, presenting empirical research on pre-schoolers creativity with tablet computers through a multimodal (intra) action analysis that emphasizes the entanglement of human and non-human agents. Employing Haraway and Barads concept of diffraction as a methodological alternative to reflexivity, the researcher creates and iteratively examines multiple multimodal transcripts of the same audio-visual data to identify how differences produce significance in research findings. This diffractive approach allows the researcher to slow down and meticulously observe intra-activity between humans and technologies, ultimately contributing a novel methodology that transfers concepts and methods from multimodality to posthumanism and reveals new layers of understanding humannon-human interactions in empirical studies."
18,"S. Kjær Jensen and B. Schirrmacher, ""Stronger together: Moving towards a combined multimodal and intermedial model,"" Multimodality & Society, 2024. [Online]. Available: https://doi.org/10.1177/26349795241259606","This article examines the synergistic possibilities between intermedial and multimodal semiotic analysis in understanding complex communication. While both research fields investigate multifaceted communicative situations, they often employ distinct methods and theoretical perspectives, which has limited their integration. The authors propose treating intermediality and multimodality as complementary, advocating for explicit articulation of their methodological and theoretical differences. Building on the work of Bateman and Ellestrom, they chart a combined analytic space where both approaches contribute. The paper illustrates their proposition through a case study focusing on the recurring use of Ride of the Valkyries in Wagners opera Die Walkure (1870), a Nazi newsreel, and Coppolas film Apocalypse Now (1979). The multimodal analysis elucidates how semiotic resources integrate within each instance, while the intermedial perspective follows the mediated transformations, illuminating how each context amplifies and alters the meaning potential of Wagners work."
19,"Hamdi Dibeklioğlu, Elif Surer, Albert Ali Salah, Thierry Dutoit, ""Behavior and usability analysis for multimodal user interfaces,"" Journal on Multimodal User Interfaces, vol. 15, pp. 335–336, 2021. DOI: https://doi.org/10.1007/s12193-021-00372-0 URL: https://link.springer.com/article/10.1007/s12193-021-00372-0","Multimodal interfaces continually present new challenges and opportunities for designers as technologies evolve and become more widely accessible, leading to diverse application scenarios. This special issue collects studies that advance the field through prototype development, user evaluation, and the integration of multimodal data and methods. Highlights include: the SIAP dataset for audio-visual personality analysis with deep learning (Giritlioglu et al.), demonstrating the role of induced behavior and cross-dataset evaluation; PLAAN (Li, Gosh, and Joshi), which leverages LSTM-DNN models and anomaly detection to enhance automated pain and protective behavior estimation from body movements; the MUMBAI dataset (Schimmel et al.) for studying social signals in board game contexts, annotated for emotional moments and personality traits; a comparative usability study of a scenario-based game generator for the CBRNe domain, evaluating both PC and VR environments (Surer et al.); and Ince et al.'s design of a drum-playing human-robot interaction game, exploring embodiment and real-time collaborationaimed toward assistive technology for children with special needs. Collectively, these studies demonstrate the application of state-of-the-art multimodal human behavior analysis in data-rich, interactive domains, contribute new public datasets, and foster broader collaboration in the field."
20,"Candy Olivia Mawalim, Shogo Okada, Yukiko I. Nakano, Masashi Unoki, ""Personality trait estimation in group discussions using multimodal analysis and speaker embedding,"" Journal on Multimodal User Interfaces, vol. 17, pp. 47–63, 2023. DOI: https://doi.org/10.1007/s12193-023-00401-0 URL: https://link.springer.com/article/10.1007/s12193-023-00401-0","This paper investigates the automatic estimation of Big Five personality traits in group discussions using multimodal analysis and transfer learning, with a focus on state-of-the-art speaker individuality features such as the i-vector speaker embedding. Experiments on Japanese (MATRICS) and European (ELEA-AV) group discussion corpora reveal that audio-related features, particularly speaker individuality representations like i-vectors and x-vectors, significantly enhance prediction accuracyachieving F1-scores above 70% for neuroticism and boosting extraversion estimation. Multimodal analyses show audio features to be most influential, while adding motion or language features provides limited improvement, with motion features mainly benefiting conscientiousness. The approach surpasses prior methods by at least 8% average F1-score, demonstrating robust transferability across languages and group contexts. Limitations include small corpus size and omission of advanced deep learning models; future directions propose expanding datasets and leveraging modern multimodal machine learning for explainability and feedback in personality-aware interfaces."
21,"Béatrice Biancardi, Maurizio Mancini, Brian Ravenet, Giovanna Varni, ""Modelling the 'transactive memory system' in multimodal multiparty interactions,"" Journal on Multimodal User Interfaces, vol. 18, no. 1, pp. 103–117, 2024. DOI: https://doi.org/10.1007/s12193-023-00399-w URL: https://link.springer.com/article/10.1007/s12193-023-00399-w","Transactive memory system (TMS) is a team emergent state reflecting members' awareness of who knows what during joint tasks. This study demonstrates that the three TMS dimensionsCredibility, Specialisation, and Coordinationcan be modeled as a linear combination of nonverbal multimodal features exhibited by the team. Findings show that these TMS dimensions correlate with such features, and increasing the number of modalities (audio, movement, spatial) improves the accuracy of this modeling. These results suggest future applications in human-centered computing where TMS can be automatically estimated from team behavioral patterns to enhance feedback and teamwork."
22,"F. Atilla, B. Klomberg, B. Cardoso, and N. Cohn, ""Background check: cross-cultural differences in the spatial context of comic scenes,"" Multimodal Communication, vol. 12, no. 3, pp. 179–189, 2023. [Online]. Available: https://www.degruyter.com/document/doi/10.1515/mc-2023-2010/html","This study investigates cultural differences in the depiction of backgrounds in comics from Japan, China, Russia, Nigeria, Spain, and the United States by annotating 6,716 panels from 60 comics. Consistent with prior cognitive research, comics from the United States, Spain, and Nigeria more frequently conveyed spatial context explicitly through detailed, depicted backgrounds, whereas Japanese, Chinese, and Russian comics favored implicit strategies such as empty backgrounds, which may serve as cognitive 'breaks' for readers. Statistical analysis using mixed model ANOVAs revealed significant interactions between country and background type, with depicted backgrounds universally common but varying in prevalence; for example, Spanish comics used depicted backgrounds more than East Asian comics, while Japanese and Russian comics used empty backgrounds more than Western and Nigerian comics. The average ""re-establishing length""the number of panels between explicit backgroundswas longest in Japanese and Russian comics, suggesting readers in these traditions infer more context, possibly reflecting broader cognitive patterns of visual attention. The results challenge universalist views of visual narrative structure and emphasize the influence of cultural cognition and visual language on how spatial relationships are constructed and understood in comics."
23,"J. A. Bateman and C.-I. Tseng, ""Multimodal discourse analysis as a method for revealing narrative strategies in news videos,"" Multimodal Communication, vol. 12, no. 3, pp. 261–285, 2023. [Online]. Available: https://www.degruyter.com/document/doi/10.1515/mc-2023-2017/html","This paper examines how narrative strategies in audiovisual news reporting can be more reliably recognized and differentiated using advancements in multimodal discourse analysis. Focusing on individualisation strategies, the authors conducted a contrastive analysis of 166 news reports from German channels Tagesschau (public) and Bild TV (private), produced between January and March 2022. They employed a framework based on multimodal cohesion and coded each news segment across nine categories, yielding a $9 \times 166$ binary data table which was analyzed using radar plots, PCA, generalized linear models, random forests, and inference trees. Results show Tagesschau uses more protagonists, while Bild TV individualizes Putin, uses more emotionalization and negative evaluation, and employs wallpapering and self-reference more intensively; both use layperson interviews and closeups, but these are not strong channel discriminators. The approach demonstrates the empirical scalability and interpretive depth of multimodal analysis, overcoming challenges of scale and variation in data. The methodology enables systematic charting and prediction of narrative strategies, offering new insight into how public and private news channels differ in their use of personalisation, emotionalisation, and framing, and surpassing previous text-centric or item-based analytic approaches. The study suggests expanding future analyses to include further narrative strategies and larger datasets to deepen understanding of news discourse, bias, and disinformation."
24,"D. Lindenberg, ""Multimodal meaning-making in student presentations: the impact of explicit feedback in a German as a foreign language classroom,"" Multimodal Communication, vol. 12, no. 3, pp. 191–206, 2023. [Online]. Available: https://www.degruyter.com/document/doi/10.1515/mc-2023-2011/html","This study investigates the effects of explicit teacher feedback on seven students' presentations about social and cultural topics in a German-as-a-foreign-language class in Japan. After submitting self-recorded draft presentations to an online platform, students received detailed feedback focusing on how their spoken language related to slide content, informed by social semiotics and systemic functional linguistics. Following a revision session, students delivered final presentations, which were video recorded and analyzed. Fourteen modified sections from both drafts and final presentations were examined using qualitative multimodal discourse analysis. The research illustrates through two student cases how supplementing slides with verbal explanations enhanced engagement via language, gaze, body orientation, and gesture, and how restructuring slides with added content clarified the presentations' key ideas. The findings highlight the importance of integrating language with visual and bodily modes for multiliteracies pedagogy in foreign language education, advocating a holistic, multimodal approach to communication."
25,"J. A. Bateman and F. Schmidt-Borcherding, ""The Communicative Effectiveness of Education Videos: Towards an Empirically-Motivated Multimodal Account,"" Multimodal Technologies and Interaction, vol. 2, no. 3, pp. 59, Sep. 2018. [Online]. Available: https://www.mdpi.com/2414-4088/2/3/59","Educational content of many kinds and from many disciplines are increasingly presented in the form of short videos made broadly accessible via platforms such as YouTube. We argue that understanding how such communicative forms function effectively (or not) demands a more thorough theoretical foundation in the principles of multimodal communication that is also capable of engaging with, and driving, empirical studies. We introduce the basic concepts adopted and discuss an empirical study showing how functional measures derived from the theory of multimodality we employ and results from a recipient-based study that we conducted align. We situate these results with respect to the state of the art in cognitive research in multimodal learning and argue that the more complex multimodal interactions and artifacts become, the more a fine-grained view of multimodal communication of the kind we propose will be essential for engaging with such media, both theoretically and empirically."
26,"T. Guntz, R. Balzarini, D. Vaufreydaz, and J. L. Crowley, ""Multimodal Observation and Classification of People Engaged in Problem Solving: Application to Chess Players,"" Multimodal Technologies and Interaction, vol. 2, no. 2, pp. 11, Jun. 2018. [Online]. Available: https://www.mdpi.com/2414-4088/2/2/11","In this paper, the authors present initial results from a pilot experiment analyzing multimodal observations of human experts solving challenging chess problems, with the aim of modeling cognitive state from eye-gaze, posture, emotion, and other physiological signals. By integrating various sensor modalities, they seek to improve detection of human awareness and emotion, with applications in domains like autonomous aging and automated training systems. Recordings of chess players addressing problems of increasing difficulty were used to estimate situational awareness and predict response efficacy. Feature selection identified key indicators from each modality, contributing to a multimodal classifier, and initial findings highlight eye-gaze, body posture, and emotion as strong predictors of awareness. The experiment further supports the reproducibility and generalizability of their equipment for studying participant interactions in screen-based problem-solving contexts."
27,"J. Lamb, ""To Boldly Go: Feedback as Digital, Multimodal Dialogue,"" Multimodal Technologies and Interaction, vol. 2, no. 3, pp. 49, Sep. 2018. [Online]. Available: https://www.mdpi.com/2414-4088/2/3/49","This article examines the role of digital, multimodal feedback in supporting learning and assessment within education, arguing that feedback conceived as a digitally mediated, ongoing dialogueincorporating multiple modes beyond traditional printcan foster imaginative and critical learning aligned with our digital society. Utilizing case studies from a postgraduate digital education program, including reflective blogging and assignments within the Second Life virtual world, the paper demonstrates that providing feedback in diverse modalities inspires students to produce sophisticated coursework. However, the creation of multimodal feedback presents challenges, including resource demands and potential conflicts with entrenched expectations for language-based academic discourse. The article situates this discussion within evolving pedagogic and institutional priorities around assessment feedback and the rise of new academic communication forms, emphasizing the importance of digitally mediated, interactive tutor-student exchanges in contemporary education."
28,"Yushan Jiang, Kanghui Ning, Zijie Pan, Xuyang Shen, Jingchao Ni, Wenchao Yu, Anderson Schneider, Haifeng Chen, Yuriy Nevmyvaka, and Dongjin Song, ""Multi-modal Time Series Analysis: A Tutorial and Survey,"" arXiv preprint arXiv:2503.13709, 2025. [Online]. Available: https://arxiv.org/abs/2503.13709","Multi-modal time series analysis, a growing research direction in data mining, addresses challenges such as data heterogeneity, modality gaps, misalignment, and noise by leveraging cross-modal interactions among diverse data types like text, images, tables, and graphs. This survey systematically categorizes over 40 methods and outlines a unified framework of cross-modal interactionsfusion, alignment, and transferenceat input, intermediate, and output levels using approaches like self-/cross-attention, graph convolution, prompt engineering with large language models (LLMs), and contrastive learning. While domain-specific and often tailored to their applications, these methods consistently surpass uni-modal baselines, especially when LLMs are integrated for contextual reasoning and alignment. Applications span healthcare (e.g., combining EHRs with clinical notes for improved patient outcome prediction), finance (e.g., stock prediction via LLM-augmented fusion of prices, news, and social media), traffic, environment, and retail, with increased interpretability and predictive power. The fields persistent challenges include reconciling modality differences, mitigating noise, and ensuring robustness to missing modalities. Future directions aim to leverage retrieval-augmented generation (RAG) for external knowledge injection, enhance generalization across domains, improve missing/noisy modality handling, and embed fairness and ethical considerations. The authors provide an up-to-date GitHub repository and emphasize a taxonomy that encourages systematic exploration and application of multi-modal time series analytics."
29,"Wenwu Zhu, Xin Wang, and Hongzhi Li, ""Multi-modal Deep Analysis for Multimedia,"" IEEE Transactions on Circuits and Systems for Video Technology, 2020. arXiv preprint arXiv:1910.04964. [Online]. Available: https://arxiv.org/abs/1910.04964 , doi: 10.1109/TCSVT.2019.2940647","This article provides a comprehensive overview of multi-modal analysis in multimedia, addressing the challenges posed by heterogeneous and multi-modal data such as texts, images, videos, and audios arising from the growth of internet and multimedia services. The paper introduces two central scientific problemsdata-driven correlational representation and knowledge-guided fusionand examines multi-modal correlational representation through multi-modal deep representation, transfer learning, and hashing approaches. It discusses knowledge-guided fusion by exploring methods for integrating domain knowledge with data and presents four key applications: multi-modal visual question answering, video summarization, visual pattern mining, and recommendation. The article concludes with insights and future research directions for advancing multi-modal multimedia analysis."
30,"Jiaqi Wang, Hanqi Jiang, Yiheng Liu, Chong Ma, Xu Zhang, Yi Pan, Mengyuan Liu, Peiran Gu, Sichen Xia, Wenjun Li, Yutong Zhang, Zihao Wu, Zhengliang Liu, Tianyang Zhong, Bao Ge, Tuo Zhang, Ning Qiang, Xintao Hu, Xi Jiang, Xin Zhang, Wei Zhang, Dinggang Shen, Tianming Liu, and Shu Zhang, ""A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks,"" arXiv preprint arXiv:2408.01319, 2024. [Online]. Available: https://arxiv.org/abs/2408.01319","This paper presents a comprehensive review of Multimodal Large Language Models (MLLMs), sophisticated AI systems capable of integrating diverse data types such as text, images, videos, audio, and physiological sequences, to tackle complex real-world applications beyond the limits of single-modality models. The paper systematically discusses the architecture of MLLMsincluding multimodal input encoders (e.g., ViT for images, HuBERT for audio), fusion mechanisms (early, intermediate, late, joint fusion), and multimodal output decodersand details how pre-trained LLMs are extended for multimodal tasks. Comparative analyses are offered across image (e.g., MiniGPT-4, InstructBLIP), video (e.g., Video-LLaMA), and audio (e.g., Qwen-Audio, SpeechGPT) domains, with tabular summaries of architectures, fusion techniques, and datasets. Key challenges identified include limited interpretability (fusion often treated as a black box), balancing comprehensive versus specialized model designs, security and ethical issues (privacy, bias), and deployment obstacles such as high computational cost and annotation quality. The authors advocate for advancements in interpretability (e.g., modality contribution analysis), development of efficient and robust models, creation of diverse datasets, incorporation of external knowledge, and strong ethical governance. By highlighting existing state-of-the-art models and future research directions, the paper serves as a valuable roadmap for the ongoing development and practical deployment of MLLMs."
31,"M. Jaritz, T.-H. Vu, R. De Charette, É. Wirbel, and P. Pérez, ""Cross-modal learning for domain adaptation in 3D semantic segmentation,"" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 45, no. 2, pp. 1533-1544, 2022. [Online]. Available: https://ieeexplore.ieee.org/document/9737217/","This paper introduces a cross-modal learning approach for domain adaptation in 3D semantic segmentation by enforcing consistency between modalities (2D images and 3D point clouds) via mutual mimicking. The proposed architecture features two independent streams (using SparseConvNet for 3D and a modified U-Net for 2D) with dual heads: a main head for accurate prediction and a mimicry head for estimating the other modalitys output. The key component is a cross-modal loss, formulated as the KL divergence between the segmentation outputs of the two modalities; this loss is applied on both labeled and unlabeled data to drive consistency. In unsupervised domain adaptation (xMUDA) and semi-supervised domain adaptation (xMoSSDA) settings, as well as their pseudo-label-augmented variants, the methods significantly outperform uni-modal adaptation baselines, as measured by mean Intersection over Union (mIoU) across diverse scenarios and datasets (nuScenes-Lidarseg, VirtualKITTI, SemanticKITTI, A2D2, Waymo Open Dataset), which include real/synthetic, different weather, and sensor variations. Ablation studies validate the necessity of the dual-head setup and the use of cross-modal loss. The dual-head consistency prevents negative transfer and improves both the weaker (2D) and stronger (3D) modalities, demonstrating robustness even in challenging domain gaps. The authors suggest generalizability to other modalities and tasks, and their code is publicly available. The methods central equations include the cross-modal loss, represented as $L_{cm} = \text{KL}(P_{2D}^{main}\; ||\; P_{3D}^{mimic}) + \text{KL}(P_{3D}^{main}\; ||\; P_{2D}^{mimic})$, enforcing prediction consistency, and supervision/pseudo-label objectives for domain adaptation."
32,"Y. Liu, G. Li, and L. Lin, ""Cross-modal causal relational reasoning for event-level visual question answering,"" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 45, no. 10, pp. 11624-11641, 2023. [Online]. Available: https://ieeexplore.ieee.org/document/10146482/","Existing visual question answering (VQA) approaches often fall short when dealing with event-level reasoning, as they are susceptible to cross-modal spurious correlations and lack the ability to model temporal, causal, and dynamic relations in video data. To overcome these shortcomings, this work introduces the Cross-Modal Causal RelatIonal Reasoning (CMCIR) framework. CMCIR employs causal intervention operations to uncover causal structures between visual and linguistic modalities, mitigating spurious associations. The framework comprises three primary modules: (i) the Causality-aware Visual-Linguistic Reasoning (CVLR) module, which uses front-door and back-door causal interventions for disentangling and correcting spurious visual-linguistic correlations; (ii) a Spatial-Temporal Transformer (STT) module that models fine-grained, temporally-extended interactions between visual and language features; and (iii) a Visual-Linguistic Feature Fusion (VLFF) module that adaptively learns global, semantically-rich cross-modal representations. Extensive evaluation across four event-level datasets demonstrates that CMCIR more effectively uncovers visual-linguistic causal relationships and delivers state-of-the-art performance in robust event-level VQA."
33,"A. Vobecky, D. Hurych, O. Siméoni, S. Gidaris, A. Bursuc, P. Pérez, and J. Sivic, ""Unsupervised Semantic Segmentation of Urban Scenes via Cross-Modal Distillation,"" International Journal of Computer Vision, vol. 133, no. 6, pp. 3519–3541, 2025. [Online]. Available: https://doi.org/10.1007/s11263-024-02320-3","This paper introduces Drive&Segment, a fully unsupervised cross-modal framework for semantic image segmentation of urban scenes, eliminating the need for manual annotations by leveraging large-scale, raw, and uncurated data collected from vehicle-mounted cameras synchronized with LiDAR sensors. The method first generates 3D object proposals from LiDAR point clouds and aligns them with image data, grouping 3D segments into semantically meaningful pseudo-classes through unsupervised clustering. A transformer-based segmentation model is then trained via cross-modal knowledge distillation, where partially annotated pixels (with these pseudo-classes) provide supervision for semantic segmentation. Further improvements involve a teacher-student framework using an exponential moving average, where soft teacher outputs refine the segmentation predictions. Tested on four benchmarks (Cityscapes, Dark Zurich, Nighttime Driving, ACDC) without fine-tuning, the approach achieves strong generalization and competitive results. The authors present detailed analyses including per-class and pixel accuracies, confusion matrices, PCA visualizations, ablations (number of clusters, LiDAR density), and qualitative assessments. Limitations include the inability to segment distant or flat classes (like sky and sidewalk) when LiDAR data is sparse or ambiguous, and challenges with semantically similar surfaces. Future directions include enhancing pseudo-annotation quality, fusing LiDAR and unsupervised image-based proposals, and exploring alternative feature clustering techniques for more robust urban scene understanding. The proposed approach demonstrates the viability of scalable, annotation-free training for perception models in autonomous driving."
34,"M. Planamente, C. Plizzari, S. A. Peirone, B. Caputo, and A. Bottino, ""Relative Norm Alignment Loss for Multimodal Learning,"" International Journal of Computer Vision, Special Issue on Multimodal Learning, vol. 133, 2025. (Note: Full citation details and URL available in the Special Issue on Multimodal Learning. Reference: https://link.springer.com/journal/11263/volumes-and-issues/133-6)","This paper addresses challenges in multi-modal learningparticularly modality heterogeneity and domain shiftby proposing the Relative Norm Alignment (RNA) loss. RNA loss targets discrepancies in mean feature norms between modalities and domains, promoting alignment both globally and at the class level: the loss is formulated as $\mathcal{L} = \mathcal{L}_C + \mathcal{L}_{\textit{RNA}}^{g}$ for basic domain adaptation, and further extended to $\mathcal{L} = \mathcal{L}_C + \mathcal{L}_{\textit{RNA}} + \lambda_d \mathcal{L}_d + \lambda_{\textit{IM}} \mathcal{L}_{\textit{IM}}$ in Unsupervised Domain Adaptation (UDA), where additional adversarial and information maximization terms further improve feature transferability. Extensive experiments across diverse datasets and modalities (e.g., action and object recognition, fatigue detection) show that RNA not only brings norms into tighter alignmentas measured by the coefficient of variationbut also enables competitive or state-of-the-art accuracy across source and unseen domains. The method is simple, computationally lightweight, and generalizes well to multiple modalities by summing pairwise losses. While most effective for balanced classes, its modular design allows for future extensions to unbalanced data cases. Overall, RNA loss is shown to be an effective, versatile approach for reducing domain shift and improving deep multi-modal classification."
35,"X.-F. Zhu, T. Xu, Z.-t. Liu, Z. Tang, X.-J. Wu, and J. Kittler, ""UniMod1K: A Dataset for Multimodal Learning with Vision, Depth, and Language,"" International Journal of Computer Vision, Special Issue on Multimodal Learning, vol. 133, 2025. (Note: Full citation details and URL available in the Special Issue on Multimodal Learning. Reference: https://link.springer.com/journal/11263/volumes-and-issues/133-6)","The paper introduces UniMod1K, a large-scale dataset designed to foster multi-modal deep learning by providing synchronized data across three modalities: vision (RGB), depth, and language. UniMod1K includes 1050 RGB-D video sequences, totaling about 2.5 million frames, with each video paired with a unique sentence description of the target object, thus addressing the scarcity of comprehensive multi-modal datasets which often cover only two modalities or single tasks. The authors demonstrate the dataset's value by tackling multi-modal tasks including RGB-D object tracking, vision-language tracking, and vision-depth-language tracking, for which they also propose new baseline methods and conduct thorough experiments. The experimental results show that training on UniMod1K advances multi-modal learning performance, supporting its potential to improve state-of-the-art methods in object tracking and monocular depth estimation. Dataset and code are publicly available at https://github.com/xuefeng-zhu5/UniMod1K."
36,"S. J. Mataraso, C. A. Espinosa, D. Seong, S. M. Reincke, E. Berson, J. D. Reiss, Y. Kim, M. Ghanem, C.-H. Shu, T. James, Y. Tan, S. Shome, I. A. Stelzer, D. Feyaerts, R. J. Wong, G. M. Shaw, M. S. Angst, B. Gaudilliere, D. K. Stevenson, and N. Aghaeepour, “A machine learning approach to leveraging electronic health records for enhanced omics analysis,” Nature Machine Intelligence, vol. 7, pp. 293–306, 2025. [Online]. Available: https://www.nature.com/articles/s42256-024-00974-9","The COMET framework introduces a novel approach to multimodal machine learning for omics studies with limited cohort sizes by leveraging transfer learning from large electronic health record (EHR) datasets. By employing an RNN-based EHR modality pretrained on large cohorts, and then adaptively blending both omics and EHR data via early and late fusion, COMET significantly enhances predictive modeling and biological discovery over traditional methods. Evaluation on a pregnancy cohort (n=61, predicting days to labor) and a cancer cohort (UK Biobank, n=559, predicting 3-year mortality) demonstrated that COMET outperformed baselines, achieving Pearson's $r=0.868$ for pregnancy and AUROC $=0.842$ for cancer, reflecting improved alignment between EHR and omics features and more biologically meaningful patient stratification. Feature importance analysis identified proteins crucial to pregnancy and cancer prognosis, while regularization studies showed superior generalization. Although limitations include the need for further scalability and applicability to more complex omics data and potential EHR data mapping errors, COMET presents a significant advance for multimodal biomedical data integration, enabling discovery from otherwise underpowered omics studies."
37,"S. R. Stahlschmidt, B. Ulfenborg, and J. Synnergren, “Multimodal deep learning for biomedical data fusion: a review,” Nature Machine Intelligence, vol. 5, pp. 351–362, 2023. [Online]. Available: https://www.nature.com/articles/s42256-023-00629-w","Biomedical data, characterized by increasing multimodality, capture complex relationships among biological processes. This paper reviews current state-of-the-art deep learning (DL)-based data fusion strategies for modeling such nonlinear relationships and proposes a detailed taxonomy to inform the selection of fusion strategies in biomedical applications. The review demonstrates that deep fusion strategies frequently outperform unimodal and shallow methods, with different subcategories exhibiting distinct advantages and limitations. Notably, intermediate fusion strategies using joint representation learning most effectively model complex biological interactions. The authors highlight gradual fusionguided by biological knowledge or search strategiesand transfer learning as promising areas for future research, particularly to address sample size limitations in multimodal datasets. As such data become more widely available, multimodal DL approaches are primed to enable training of holistic models capable of elucidating the regulatory dynamics underlying health and disease."
38,"D. Ding, S. Li, B. Narasimhan, and R. Tibshirani, “Cooperative learning for multiview analysis,” Nature Machine Intelligence, vol. 4, pp. 263–271, 2022. [Online]. Available: https://www.nature.com/articles/s42256-022-00497-6","This paper introduces cooperative learning, a supervised multiview data fusion method combining standard squared-error loss with an agreement penalty between prediction functions from different feature sets (""views""), such as genomics, proteomics, and metabolomics in biological data. The approach is formalized by optimizing 
$$
\min E\left[\frac{1}{2}(y - f_X(X) - f_Z(Z))^2 + \frac{\rho}{2}(f_X(X) - f_Z(Z))^2\right],
$$
where the first term is the prediction error, and the second encourages prediction agreement across modalities, parameterized by $\rho$. In cooperative regularized linear regression, lasso penalties enforce feature sparsity and the objective becomes
$$
\min \frac{1}{2}\|y - X\theta_x - Z\theta_z\|^2 + \frac{\rho}{2}\|(X\theta_x - Z\theta_z)\|^2 + \lambda(\|\theta_x\|_1 + \|\theta_z\|_1).
$$
The method is modular, allowing distinct learning algorithms (e.g., neural nets, random forests) per view, and adaptively tunes $\rho$ for optimal agreement using validation. Simulation experiments demonstrate superior prediction error (lower test MSE) versus early and late data fusion, especially when data views share correlated latent factors. For example, in a labor onset multiomics dataset, cooperative learning selected more features and outperformed other approaches, identifying novel signals like C1q. Results are summarized in the following table:
\[
\begin{tabular}{lccc}
\text{Method} & \text{Test MSE (Mean  Std)} & \text{Relative to Early Fusion} & \text{Features Selected} \\
\hline
\text{Separate Proteomics} & 475.51 \pm 80.89 & 69.14 \pm 81.44 & 26 \\
\text{Separate Metabolomics} & 381.13 \pm 36.88 & -25.24 \pm 30.91 & 11 \\
\text{Early Fusion} & 406.37 \pm 44.77 & 0 \pm 0 & 15 \\
\text{Late Fusion} & 493.34 \pm 63.44 & 86.97 \pm 68.13 & 21 \\
\text{Cooperative Learning} & 335.84 \pm 38.51 & -70.53 \pm 32.60 & 52 \\
\end{tabular}
\]
Cooperative learning generalizes and blends standard fusion methods, proving most effective when views are correlated with relevant signal and providing a framework for flexible, high-accuracy multiomic data integration."
39,"Y. He, L. Zheng, X. Shi, and T. Huang, ""Efficient Modality Selection in Multimodal Learning,"" Journal of Machine Learning Research, vol. 25, no. 61, pp. 1-53, 2024. [Online]. Available: https://www.jmlr.org/papers/volume25/23-0439/23-0439.pdf","Multimodal learning seeks to leverage data from various modalities, but using all modalities may be computationally infeasible or redundant due to overlapping information. This paper addresses the modality selection problemselecting the most informative subset of modalities under cardinality constraints. The authors introduce a unified theoretical framework to quantify modality learning utility, incorporate flexible dependence assumptions for heterogeneous data, and derive an efficient greedy modality selection algorithm through submodular maximization, providing optimality guarantees. They also relate marginal-contribution-based importance scores (e.g., Shapley value) from feature selection to the context of modality selection. Experimental validation on two synthetic and four real-world datasets confirms the effectiveness of their theoretical results and algorithms for diverse multimodal data scenarios."
40,"D. Benielli, H. Berry, and J. Morlier, ""scikit-multimodallearn: A Python Toolbox for Multimodal Machine Learning,"" Journal of Machine Learning Research, vol. 23, no. 279, pp. 1-6, 2022. [Online]. Available: https://www.jmlr.org/papers/volume23/21-0791/21-0791.pdf","scikit-multimodallearn is a Python library designed for multimodal supervised learning, released under a Free BSD license and fully compatible with the widely used scikit-learn toolbox. The paper introduces the features of the library, including specialized formatting for multimodal data as well as algorithms tailored for classification and regression tasks involving multiple data modalities. Additionally, the use of the library is illustrated through various use cases and practical examples."
41,"P. Goyal, S. Sahu, S. Ghosh, and C. Lee, “Cross-modal Learning for Multi-modal Video Categorization,” arXiv preprint arXiv:2003.03501, 2020. [Online]. Available: https://arxiv.org/abs/2003.03501","Multi-modal machine learning models can integrate diverse data modalities such as video, audio, and text, enhancing tasks like object detection, scene understanding, and activity recognition. This paper addresses video categorization by introducing a ""cross-modal learning"" approach, wherein one modality informs another only when there is detected correlationachieved through a correlation tower that guides the main multi-modal video categorization model. The cross-modal learning principle is shown to be adaptable to architectures like RNNs, Transformers, and NetVLAD. Experimental results indicate that incorporating cross-modal learning enables these multi-modal models to outperform existing state-of-the-art baseline methods for video categorization."
42,"S. S. Srinivas and V. Runkana, “Cross-Modal Learning for Chemistry Property Prediction: Large Language Models Meet Graph Machine Learning,” arXiv preprint arXiv:2408.14964, 2024. [Online]. Available: https://arxiv.org/abs/2408.14964","In the field of chemistry, the objective is to create novel molecules with desired properties, facilitating accurate property predictions for applications such as material design and drug screening. However, existing graph deep learning methods face limitations that curb their expressive power. To address this, we explore the integration of vast molecular domain knowledge from Large Language Models (LLMs) with the complementary strengths of Graph Neural Networks (GNNs) to enhance performance in property prediction tasks. We introduce a Multi-Modal Fusion (MMF) framework that synergistically harnesses the analytical prowess of GNNs and the linguistic generative and predictive abilities of LLMs, thereby improving accuracy and robustness in predicting molecular properties. Our framework combines the effectiveness of GNNs in modeling graph-structured data with the zero-shot and few-shot learning capabilities of LLMs, enabling improved predictions while reducing the risk of overfitting. Furthermore, our approach effectively addresses distributional shifts, a common challenge in real-world applications, and showcases the efficacy of learning cross-modal representations, surpassing state-of-the-art baselines on benchmark datasets for property prediction tasks. In the rapidly evolving field of computational chemistry, the pressing need for methodologies with higher accuracy and robustness in predicting molecular properties is undeniable. Our pioneering efforts in this study have introduced the Multi-Modal Fusion (MMF) framework, which synergistically amalgamates LLMs and GNNs to enhance the accuracy of molecular property predictions. Our approach not only improves predictions but also reduces the likelihood of overfitting, surpassing existing benchmarks in property prediction tasks. Our results on benchmark datasets confirm our hypothesis that fusing information from text and graph-based modalities can significantly enhance performance. This breakthrough opens new avenues for scientific discovery, advancing computational chemistry applications across domains to shape the next generation of tools and insights in chemistry."
43,"Z. Lin, S. Yu, Z. Kuang, D. Pathak, and D. Ramanan, “Multimodality Helps Unimodality: Cross-Modal Few-Shot Learning with Multimodal Models,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), arXiv preprint arXiv:2301.06267, 2023. [Online]. Available: https://arxiv.org/abs/2301.06267","This paper addresses the challenge of few-shot learning by leveraging information across multiple modalities, such as vision, language, and audio, to improve sample efficiency and classification performance in unimodal tasks. The authors propose a simple yet effective cross-modal adaptation technique: treating each available modality as an extra training example, thus trivially converting an $n$-shot to an $(n+1)$-shot problem. Built upon multimodal foundation models like CLIP, which align representations across modalities, the approach enables state-of-the-art results on 11 visual classification benchmarks and introduces a novel audiovisual few-shot benchmark (ImageNet-ESC). The methodology generalizes loss functions to accommodate modality-specific encoders, allows seamless multimodal inference, and can be readily combined with methods such as prefix tuning, adapters, and ensemble classifiers. Empirical results, shown in detailed quantitative tables and qualitative analyses, demonstrate that cross-modal adaptation outperforms more complex baselines while remaining lightweight and robust to distribution shift. However, the success of this method depends critically on well-aligned and pre-trained multimodal encoders; misalignment or insufficient trainingespecially in the audio domainposes performance challenges. Cross-modal training emerges as a new baseline for adapting foundation models, with future directions including scaling pretraining, automated prompt generation, and expanding to additional tasks and modalities."
44,"O. Aerts, S. W. Griffiths, M. W. A. van Timmeren, et al., “The Image Biomarker Standardisation Initiative: Standardized Quantitative Radiomics for High Throughput Image-based Phenotyping,” Radiology, vol. 295, no. 2, pp. 328-338, May 2020. [Online]. Available: https://pubs.rsna.org/doi/10.1148/radiol.2020191145","This study, conducted by the Image Biomarker Standardization Initiative (IBSI), addressed the challenge of inconsistent radiomics feature computation in medical imaging by standardizing the definitions and reference values for 174 commonly used features. Twenty-five research teams participated in a three-phase process: initial feature computation without additional image processing (phase I), reference value determination under predefined image processing configurations (phase II), and prospective validation using multimodal images from a soft-tissue sarcoma cohort (phase III). Consensus on feature values was iteratively improved, with strong or better agreement ultimately achieved for 95.1% (phase I) and 90.6% (phase II) of features, corresponding to standardized values for 169 of 174 features. Validation demonstrated excellent reproducibility for most features across CT, PET, and MRI modalities. The work enables software compliance checks, fosters reproducibility (as measured by intraclass correlation coefficients), and provides a foundation for clinical translation of radiomics, though challenges remain for complex algorithms and modality-specific processing. The IBSI continues to expand this standardization framework to encompass additional features and image processing methods, promoting robust and harmonized radiomics analysis."
45,"F. Sollini, R. Antunovic, A. Chiti, and H. J. W. L. Aerts, “PET Radiomics in NSCLC: State of the Art and a Proposal for Harmonization of Methodology,” Radiology, vol. 298, no. 2, pp. 548-560, Feb. 2021. [Online]. Available: https://pubs.rsna.org/doi/10.1148/radiol.2021200616","This paper provides a comprehensive review of the current state-of-the-art in texture analysis using FDG-PET/CT imaging for non-small cell lung cancer (NSCLC), emphasizing its clinical roles in tumor staging, prognosis, and treatment response prediction. Traditional metrics like standardized uptake value (SUV), metabolic tumor volume (MTV), and total lesion glycolysis (TLG) are discussed alongside emerging evidence that PET/CT-based texture analysis (radiomics) offers additional prognostic and diagnostic value by capturing tumor heterogeneity. The methods entail a systematic literature review (38 articles, split into technical/methodological and clinical groups) to synthesize findings about nomenclature, technical variability, segmentation, acquisition, and the clinical utility of texture featuressummarized in comprehensive tables. Results indicate texture analysis holds promise, especially for prognostication and treatment response, but the field is hindered by diverse methodologies, non-standardized feature definitions, and poor reporting practices, severely affecting reproducibility and translation to clinical settings. Key challenges include inconsistent feature calculation, segmentation, acquisition, lack of robust reporting, insufficient validation, and an incomplete understanding of the biological meaning of texture metrics. The review proposes a set of standardized methodological stepscovering scanner parameters, segmentation, feature extraction, and validation (detailed in Table 4)to harmonize future research, and advocates for integration with genomics and clinical data for maximum predictive power. Conclusively, the authors assert that standardization is essential for leveraging PET/CT texture analysis as a non-invasive tool to characterize lung lesions and guide clinical decision-making in NSCLC. Supplementary materials with nomenclature and formulas are available online."
46,"A. Hope, C. F. Dietrich, L. Q. Zhou, D. L. McFarlane, R. J. Gillies, and H. Hricak, “Radiomics: Images Are More Than Pictures, They Are Data,” Radiology, vol. 278, no. 2, pp. 563–577, Feb. 2016. [Online]. Available: https://pubs.rsna.org/doi/10.1148/radiol.2015151169","Radiomics transforms routine medical images into mineable, high-dimensional quantitative data using advanced pattern recognition and machine learning methodologies, surpassing traditional visual interpretation. This process involves image acquisition, precise segmentation, extraction of features (intensity, shape, texture, higher-order statistics), database curation, and classifier modelingoften integrating clinical and genomic metadata. In oncology, radiomics has demonstrated the ability to correlate features from CT, MR, and PET with gene expression, tumor phenotype, and microenvironment, producing validated predictive and prognostic biomarkers (e.g., stratifying prostate cancer aggressiveness or predicting therapy response). Radiogenomic analyses further show that imaging features can mirror gene expression profiles. The approach faces challenges in reproducibility, big data management, standardization, data sharing, and integration with clinical workflows; overcoming these necessitates standardized protocols, multicenter collaboration, and health informatics solutions. Ultimately, radiomics aims to enhance precision medicine by routinely combining radiologic quantitative features with patient datasets to create robust clinical decision support tools that surpass conventional diagnostics and monitoring."
47,"Q. Xie, Y. Li, N. He, M. Ning, K. Ma, G. Wang, Y. Lian, and Y. Zheng, ""Unsupervised Domain Adaptation for Medical Image Segmentation by Disentanglement Learning and Self-Training,"" IEEE Transactions on Medical Imaging, vol. 43, no. 1, pp. 4-14, Jan. 2024. [Online]. Available: https://doi.org/10.1109/TMI.2023.3324198","Unsupervised domain adaptation (UDA) for medical image segmentation is addressed with the proposed DLaST framework, which employs disentanglement learning to decompose images into domain-invariant anatomical and domain-specific modality features. A novel shape constraint is introduced to enhance adaptation performance, and a self-training strategy is utilized that combines adversarial learning with pseudo labeling to adaptively improve target domain segmentation and align features in the anatomy space. Experimental validation across cardiac, abdominal, and brain datasets demonstrates state-of-the-art segmentation results, indicating the effectiveness of DLaST compared to existing UDA methods."
48,"Z. Chen, Y. Zheng, and J. C. Gee, ""TransMatch: A Transformer-Based Multilevel Dual-Stream Feature Matching Network for Unsupervised Deformable Image Registration,"" IEEE Transactions on Medical Imaging, vol. 43, no. 1, pp. 15-27, Jan. 2024. [Online]. Available: https://doi.org/10.1109/TMI.2023.3324623","Feature matching is vital for feature-based image registration, particularly in deformable scenarios where traditional methods rely on explicit but time-consuming iterative matching of image regions. While recent learning-based approaches like VoxelMorph and TransMorph streamline this process, they typically employ a single-stream architecture where feature correspondence is learned implicitly. This paper introduces TransMatch, a novel end-to-end dual-stream unsupervised framework in which each input image is processed by an independent branch for feature extraction. Explicit multilevel feature matching is then performed via a query-key matching mechanism inspired by the self-attention module of Transformers. Evaluated on three 3D brain MR datasets (LPBA40, IXI, and OASIS), TransMatch achieves state-of-the-art performance compared to established methods such as SyN, NiftyReg, VoxelMorph, CycleMorph, ViT-V-Net, and TransMorph, demonstrating its efficacy for deformable medical image registration."
49,"J. Li, P. Zhang, T. Wang, L. Zhu, R. Liu, X. Yang, K. Wang, D. Shen, and B. Sheng, ""DSMT-Net: Dual Self-Supervised Multi-Operator Transformation for Multi-Source Endoscopic Ultrasound Diagnosis,"" IEEE Transactions on Medical Imaging, vol. 43, no. 1, pp. 64-75, Jan. 2024. [Online]. Available: https://doi.org/10.1109/TMI.2023.3324373","Pancreatic cancer has the worst prognosis among all cancers, and both endoscopic ultrasound (EUS) assessment and deep learning classification of EUS images face challenges due to inter-grader variability, variable image sources, and the laborious nature of manual labeling. To overcome these, the paper introduces the Dual Self-supervised Multi-Operator Transformation Network (DSMT-Net), which employs a multi-operator transformation approach for standardizing regions of interest and removing irrelevant pixels, and incorporates a transformer-based dual self-supervised network to leverage unlabeled EUS images in pre-training for tasks such as classification, detection, and segmentation. A large-scale dataset (LEPset) with 3,500 labeled EUS images and 8,000 unlabeled images was curated for model development. DSMT-Net, also tested on breast cancer data, demonstrated significant improvement over state-of-the-art deep learning models, enhancing diagnostic accuracy for both pancreatic and breast cancers."
50,"G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian, J. A. van der Laak, B. van Ginneken, C. I. Sánchez, ""A survey on deep learning in medical image analysis,"" Medical Image Analysis, vol. 42, pp. 60–88, Dec. 2017. doi: 10.1016/j.media.2017.07.005 Available: https://www.sciencedirect.com/science/article/pii/S1361841517301130","Deep learning, especially convolutional neural networks (CNNs), has rapidly become central to medical image analysis, transforming tasks such as classification, detection, segmentation, and registration across domains like neuroimaging, retinal, pulmonary, pathology, cardiac, and musculoskeletal imaging. The paper systematically introduces key deep learning architecturesincluding U-Net, multi-stream and 3D CNNs, RNNs, auto-encoders, generative adversarial networks (GANs), and associated hardware/software frameworkshighlighting their adaptation to various use cases and anatomical domains. Reviewing over 300 studies, the authors document state-of-the-art advances, public benchmarks, and practical successes, often with CNN-based systems achieving or surpassing expert-level performance for well-annotated, homogeneous tasks such as diabetic retinopathy detection and dermoscopy. However, persistent challenges remain: the scarcity and noise of expert annotations, class imbalance, the heterogeneity of medical conditions, limited generalization to rare subclasses, underexplored integration of multi-modal/temporal data, difficulties in translating 2D vision architectures to 3D/4D images, lack of model explainability, and hardware constraints on large-scale volumetric data. Addressing these hurdles necessitates advancements in unsupervised and transfer learning, uncertainty estimation (e.g., through custom loss functions involving uncertainty terms), model transparency, more sophisticated architectures for multi-modal and high-dimensional data, and automated structured annotation generation. With continued innovation along these lines, deep learnings transformative impact on medical image analysis and broader clinical practice is expected to accelerate."
51,"H. R. Roth, X. Zhuang, D. Shen, C. Shen, ""Federated learning for medical image analysis,"" Medical Image Analysis, vol. 75, 102298, Jun. 2022. doi: 10.1016/j.media.2021.102298 Available: https://www.sciencedirect.com/science/article/pii/S1361841521003082","This paper presents a comprehensive survey of federated learning (FL) approaches in medical image analysis, a field that faces the persistent challenge of small sample sizes due to data privacy regulations like HIPAA and GDPR. FL offers a solution by enabling collaborative model training without cross-site data sharing. The authors systematically compiled literature from 20172023 using major academic databases, categorizing FL methods into client-end, server-end, and communication-focused strategies, and reviewed benchmark datasets (e.g., ADNI, BraTS, CheXpert) and software platforms (e.g., PySyft, OpenFL). Empirical evaluations used the ADNI dataset, comparing methods such as FedAvg, FedProx, and FedSGD for Alzheimers Disease classification. Results (using metrics ACC, SEN, SPE, AUC) indicate that federated approaches, especially weight aggregation (FedAvg, FedProx), achieved satisfactory performance, closely rivaling centralized Mix methods and outperforming traditional cross-site approaches. The paper identifies key challengesdata heterogeneity, privacy risks, technological constraints, and long-term sustainabilityand outlines future research in areas such as federated domain adaptation, multi-modal fusion, model generalizability, weakly-supervised learning, and FL system security with technologies like blockchain. The survey aims to clarify the fields progress, open challenges, and opportunities to stimulate further research in secure, scalable medical image analysis."
52,"S. Bakas, M. Reyes, A. Jakab, S. Bauer, M. Rempfler, A. Crimi, R. Shinohara, et al., ""Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the BRATS challenge,"" Medical Image Analysis, vol. 55, pp. 80–91, Jul. 2019. doi: 10.1016/j.media.2019.04.015 Available: https://www.sciencedirect.com/science/article/pii/S1361841519301159","Gliomas, the most prevalent primary brain malignancies, display significant heterogeneity in aggressiveness, prognosis, and histologic sub-regionssuch as peritumoral edema, necrotic core, and enhancing/non-enhancing tumor areaseach exhibiting distinct intensity profiles in multi-parametric MRI (mpMRI) scans, which correspond to different biological characteristics. This variability complicates surgical resection and increases the importance of accurately quantifying residual tumor and identifying progression in longitudinal imaging, beyond standard RECIST/RANO criteria. Precise segmentation of these sub-regions is increasingly recognized as crucial for quantitative analyses aimed at predicting patient overall survival. This study reviews state-of-the-art machine learning methods applied in the seven most recent BraTS challenges (20122018), focusing on: (i) segmentation of glioma sub-regions in pre-operative mpMRI; (ii) assessment of tumor progression through tracking sub-region growth; and (iii) overall survival prediction following gross total resection. The paper also evaluates the challenge of choosing optimal ML algorithms as both the BraTS dataset and the participating methods continue to evolve across multi-institutional contexts."
53,"X. Li, Y. Guo, S. Huang, F. Wang, C. Dai, J. Zhou, and D. Lin, ""A CT-based intratumoral and peritumoral radiomics nomogram for postoperative recurrence risk stratification in localized clear cell renal cell carcinoma,"" BMC Medical Imaging, vol. 25, no. 1, p. 167, 2025. [Online]. Available: https://bmcmedimaging.biomedcentral.com/articles/10.1186/s12880-024-01133-x","This study developed and validated a CT-based radiomics nomogram that combines intratumoral and peritumoral radiomics features with clinical factors to improve prediction of postoperative recurrence risk in localized clear cell renal cell carcinoma (ccRCC). In a two-center cohort of 447 patients, radiomics features were extracted from preoperative CT within the tumor and concentric peritumoral regions (3 mm and 5 mm expansions). Using LASSO Cox regression, the best-performing radiomics model (RM) incorporated features from a 5 mm peritumoral region (IPAT 5mm), achieving a C-index of 0.924 (internal validation set, IVS) and 0.952 (external validation set, EVS) for predicting recurrence-free survival (RFS). The fusion model (FM)integrating the IPAT 5mm Radscore and clinical predictors (age, tumor grade, p-T and p-N stage)exhibited superior prognostic accuracy in the IVS (C-index: 0.938, $p = 0.03$ vs. clinical model), significantly outperforming the established SSIGN risk score (C-index: 0.938 vs. 0.886, $p < 0.001$). Decision curve analysis demonstrated higher clinical benefit for the FM and RM compared to clinical models, and Kaplan-Meier analysis showed clear RFS stratification. The findings highlight the added value of peritumoral radiomics for recurrence prediction, supporting personalized management. Study limitations include retrospective design, small external validation cohort, and focus on arterial-phase imaging. Future work will expand multi-center validation, refine segmentation approaches, and integrate multi-phase imaging to further enhance generalizability."
54,"H. Laçi, K. Sevrani, and S. Iqbal, ""Deep learning approaches for classification tasks in medical X-ray, MRI, and ultrasound images: a scoping review,"" BMC Medical Imaging, vol. 25, no. 1, p. 156, 2025. [Online]. Available: https://bmcmedimaging.biomedcentral.com/articles/10.1186/s12880-024-01122-0","This scoping review systematically surveys the application of deep learning for disease classification using X-ray, MRI, and Ultrasound images, selecting 80 studies published between 2014 and 2024 through a rigorous PRISMA-ScR methodology. Most studies focused on lung, brain, and mammary gland pathologies, with X-ray being the dominant modality and datasets typically containing 1,000 to 10,000 images; the shift from private to public datasets increased with dataset size. Preprocessing (e.g., normalization, resizing, gray-scaling, denoising) and augmentation (e.g., rotation, flipping, zooming) methods were prevalent, and custom convolutional neural networks (CNNs), often implemented in TensorFlow with Keras or Google Colab, formed the backbone of most classification tasks. Architecturally, 54% used ReLU or LeakyReLU activations in hidden layers, Softmax at the output, and Adam as the optimizer (46%), with typical GPU memory requirements of 16GB64GB for training. Core limitations across the literature include small, imbalanced datasets, lack of patient historical information, single-modality data, binary (versus multi-class) classification, annotation errors, and limited computing resources. To address these, recommendations include advanced augmentation (SMOTE, DARI, cGAN), leveraging pre-trained models, integrating Explainable AI for interpretability, utilizing historical and structured patient data, and expanding to multi-institutional, multi-modal datasets. The study highlights open challenges in generalizability, interpretability, and scalability, advocating for broader disease targeting, anonymization techniques, and multi-modal, multi-organs studies to align deep learning models with real-world clinical complexity."
55,"F. Meng, T. Zhang, Y. Pan, X. Kan, Y. Xia, M. Xu, J. Cai, F. Liu, and Y. Ge, ""A deep learning algorithm for automated adrenal gland segmentation on non-contrast CT images,"" BMC Medical Imaging, vol. 25, no. 1, p. 142, 2025. [Online]. Available: https://bmcmedimaging.biomedcentral.com/articles/10.1186/s12880-024-01094-1","This study developed and validated a deep learning (DL) model using the nnU-Net framework for automated segmentation of adrenal glands on non-contrast CT images, addressing the challenges of manual delineation due to the glands small size, anatomical variability, and low tissue contrast. The model was trained on 1,301 annotated CT scans, achieving high segmentation accuracy with median Dice Similarity Coefficients (DSC) of 0.899 for the left and 0.904 for the right adrenal gland in test sets, and comparable performance in an independent set. Evaluation against manual annotations from five radiologists demonstrated no significant difference in segmentation accuracy (P = 0.541). Applied to a large dataset of 2,000 normal subjects, the model enabled a robust analysis showing that adrenal gland volume increases with age up to 4060 years (peaking at $\sim$5.2~cm$^3$ for males and 4.8~cm$^3$ for females), then declines in older age groups, with males consistently exhibiting larger gland volumes ($\Delta = 0.4$$0.7$~cm$^3$, $P < 0.001$). These findings provide reference standards for healthy adrenal volumes and demonstrate that the DL model can efficiently and objectively segment adrenal glands, supporting large-scale morphometric studies and potentially aiding clinical assessment of adrenal disorders. Limitations include the single-center, retrospective study design, exclusion of ambiguous cases (possibly inflating performance), and male-dominated dataset, with future plans to enhance generalizability and robustness via multi-center and public dataset validation and analysis of challenging cases."
56,"F. H. Linden, M. Boesen, E. Høegh-schmidt, J. U. Nybing, R. B. Mainz Hansen, L. H. Persson Kopp, M. N. Thomsen, M. W. Brejnebøl, ""External Validation of an Automated Segmentation Tool for Abdominal Fat Tissue using DIXON MRI: Data from the CutDM trial,"" medRxiv, 2025. [Online]. Available: https://doi.org/10.1101/2025.05.14.25327583","This study addresses the challenge of efficiently segmenting and quantifying visceral adipose tissue (VAT) and subcutaneous adipose tissue (SAT), which is significant for evaluating metabolic disease risk and monitoring treatments. The traditional manual segmentation approach of the abdominal DIXON fat images between the cephalic part of L3 and caudal part of L5 vertebrae is accurate but hindered by labor intensity and variability. The authors propose enhancing the existing open-source FatSegNet tool by adding an L3-L5 delimiter model, aiming to automate the segmentation pipeline from start to finish. In the methods, two experienced readers manually segment VAT and SAT on mDIXON QUANT images from 32 overweight or obese participants with type 2 diabetes, reflecting the CUTDm trial population. The automated AI tool's segmentations will be compared to the scan-level mean of the manual readers as the reference standard, with 95% confidence intervals used for diagnostic accuracy assessment. The study complies with ethical standards and is registered (NCT05330247), with no conflicts of interest or funding reported. Scalability, inter-reader variability, and the lack of embedded localizers in current tools are identified as core challenges addressed by the proposed pipeline."
57,"E. H. P. Pooch, G. Agrotis, L. Cai, M. Emberton, T. T. Shah, H. U. Ahmed, R. G. H. Beets-Tan, S. Benson, T. Janssen, I. G. Schoots, ""Semi-Supervised Learning in Prostate MRI Tumor Segmentation Approaches Fully-Supervised Performance on External Validation,"" medRxiv, 2025. [Online]. Available: https://doi.org/10.1101/2025.05.13.25327456","This study compared semi-supervised and fully-supervised learning models for aggressive prostate cancer segmentation on MRI, leveraging 1500 PI-CAI challenge training subset scans with human and AI-generated annotations. The proposed semi-supervised mtU-Net, combining pseudo-labeling and consistency regularization, was evaluated against supervised nnU-Net (trained solely with human annotations) and semi-supervised nnU-Net (trained on both human and AI-generated annotations), with external validation performed on PROMIS (n=574) and Prostate158 (n=158) datasets. Performance metrics included area under the curve (AUC) and average precision (AP). Fully-supervised nnU-Net achieved the best internal and external test set results (e.g., PROMIS: AUC=0.70, AP=0.24), but the semi-supervised mtU-Net closely approached this performance externally (e.g., PROMIS: AUC=0.66, AP=0.20; Prostate158: AUC=0.86, AP=0.58) and significantly outperformed the supervised baseline (PROMIS p=0.024, Prostate158 p=0.007). The results demonstrate that incorporating AI-annotated data and leveraging semi-supervised strategies can nearly reach fully-supervised performance in external datasets, thus reducing dependence on extensive expert annotations in prostate MRI tumor segmentation without compromising diagnostic accuracy."
58,"A. Kumar, P. Nandakishore, A. J. Gordon, E. Baum, J. Madhok, Y. Duanmu, J. Kugler, ""Creation of an Open-Access Lung Ultrasound Image Database For Deep Learning and Neural Network Applications,"" medRxiv, 2025. [Online]. Available: https://doi.org/10.1101/2025.05.09.25327337","Background: Lung ultrasound (LUS) offers advantages over traditional imaging for diagnosing pulmonary conditions, with superior accuracy compared to chest X-ray and similar performance to CT at lower cost. Despite these benefits, widespread adoption is limited by operator dependency, moderate interrater reliability, and training requirements. Deep learning (DL) could potentially address these challenges, but development of effective algorithms is hindered by the scarcity of comprehensive image repositories with proper metadata. 

Methods: We created an open-source dataset of LUS images derived a multi-center study involving N=226 adult patients presenting with respiratory symptoms to emergency departments between March 2020 and April 2022. Images were acquired using a standardized scanning protocol (12-zone or modified 8-zone) with various point-of-care ultrasound devices. Three blinded researchers independently analyzed each image following consensus guidelines, with disagreements adjudicated to provide definitive interpretations. Videos were pre-processed to remove identifiers, and frames were extracted and resized to 128128 pixels. 

Results: The dataset contains 1,874 video clips comprising 303,977 frames. Half of the participants (50%) had COVID-19 pneumonia. Among all clips, 66% contained no abnormalities, 18% contained B-lines, 4.5% contained consolidations, 6.4% contained both B-lines and consolidations, and 5.2% had indeterminate findings. Pathological findings varied significantly by lung zone, with anterior zones more frequently normal and less likely to show consolidations compared to lateral and posterior zones. 

Discussion: This dataset represents one of the largest annotated LUS repositories to date, including both COVID-19 and non-COVID-19 patients. The comprehensive metadata and expert interpretations enhance its utility for DL applications. Despite limitations including potential device-specific characteristics and COVID-19 predominance, this repository provides a valuable resource for developing AI tools to improve LUS acquisition and interpretation."
59,"C. M. Alonso, M. Llop, C. Sargas, L. Pedrola, J. Panadero, D. Hervás, J. Cervera, E. Such, M. Ibáñez, R. Ayala, J. Martínez-López, E. Onecha, I. de Juan, S. Palanca, D. Martínez-Cuadrón, R. Rodríguez-Veiga, B. Boluda, P. Montesinos, G. Sanz, M. A. Sanz, and E. Barragán, ""Clinical Utility of a Next-Generation Sequencing Panel for Acute Myeloid Leukemia Diagnostics,"" The Journal of Molecular Diagnostics, vol. 21, no. 2, pp. 228-240, Mar. 2019. doi: 10.1016/j.jmoldx.2018.09.009 Available: https://pubmed.ncbi.nlm.nih.gov/30576870/","Next-generation sequencing (NGS) has significantly advanced the molecular characterization of acute myeloid leukemia (AML), but clinical application remains challenging. This study evaluated a 19-gene AML-targeted NGS panel in 162 patients and found it achieved exceptional technical metrics, including a median read depth exceeding 2000, 88% on-target reads, and above 93% uniformity, with no significant strand bias. The assay demonstrated high sensitivity and specificity at clinical variant allele frequency cutoffs (3% for point mutations and 5% for INDELs), identifying 339 variants (36% INDELs, 64% SNVs) and yielding 100% concordance with conventional methods while uncovering additional relevant mutations. Importantly, all patients were classifiable under the 2016 WHO diagnostic schema and nearly all conformed to the 2017 European LeukemiaNet and Genomic prognostic classifications. The validated approach shows that compact, targeted NGS panels provide reliable, actionable molecular insights to support AML diagnosis and treatment decisions per current clinical standards."
60,"L. J. Jennings, M. E. Arcila, C. Corless, S. Kamel-Reid, I. M. Lubin, J. Pfeifer, R. L. Temple-Smolkin, K. V. Voelkerding, and M. N. Nikiforova, ""Guidelines for Validation of Next-Generation Sequencing-Based Oncology Panels: A Joint Consensus Recommendation of the Association for Molecular Pathology and College of American Pathologists,"" The Journal of Molecular Diagnostics, vol. 19, no. 3, pp. 341-365, May 2017. doi: 10.1016/j.jmoldx.2017.01.011 Available: https://pubmed.ncbi.nlm.nih.gov/28341590/","This guideline provides consensus recommendations for analytical validation and ongoing quality monitoring of next-generation sequencing (NGS) gene panel testing of somatic variants in oncology, developed by a working group from the Association of Molecular Pathology and the College of American Pathologists. The document focuses on targeted gene panels used in solid tumors and hematological malignancies, emphasizing an error-based approach throughout the analytical process to identify and mitigate sources of error via test design, validation, and quality controls. Key methodological components include sample and library preparation, sequencing, and a bioinformatics pipeline covering base calling, read alignment, variant identification, and annotation. Recommendations address panel content selection, rationale for optimization and familiarization phases prior to validation, use of well-characterized reference cell lines and materials, determination of minimal depth of coverage (e.g., $>250$ reads per tested amplicon or target), and requirement for at least 59 samples to assess quality metrics and performance, with positive percentage agreement (PPA) and positive predictive value (PPV) documented for each variant type. Additional guidance is provided for ongoing quality control, proficiency testing, and thorough documentation requirements. The guideline highlights the unique advantage of targeted NGS for simultaneously detecting multiple somatic alterations, its rapid adoption, and the inherent challenges such as sensitivity, specificity, and need for robust validation, aiming to ensure high-quality sequencing results for patient care even amid ongoing technological advances."
61,"E. M. Kudalkar, N. A. M. Almontashiri, C. Huang, B. Anekella, M. Bowser, E. Hynes, R. Garlick, and B. H. Funke, ""Multiplexed Reference Materials as Controls for Diagnostic Next-Generation Sequencing: A Pilot Investigating Applications for Hypertrophic Cardiomyopathy,"" The Journal of Molecular Diagnostics, vol. 18, no. 6, pp. 882-889, Nov. 2016. doi: 10.1016/j.jmoldx.2016.07.005 Available: https://pubmed.ncbi.nlm.nih.gov/27639548/","Diagnostic next-generation sequencing (NGS) panels for hypertrophic cardiomyopathy (HCM) face significant challenges in test validation and quality control due to the scarcity and cost of obtaining patient-derived reference samples with prevalent pathogenic variants. To address this, the study piloted the use of expert-designed, multiplexed controls by spiking biosynthetic DNA fragmentseach carrying one of 10 common pathogenic or technically challenging variants from key HCM genesinto reference human genomic DNA, adjusting the allelic fraction to approximate heterozygous germline percentages (45%, 50%, 55%). NGS analysis in quadruplicate showed that variant detection in these controls was essentially indistinguishable from patient-derived samples, except for a known challenging 25-bp indel in MYBPC3, underscoring the importance of including such variants to rigorously assess NGS assay performance. These biosynthetic multiplexed controls offer practical advantages over alternatives, such as in silico or CRISPR-edited materials, due to their engineerability, precise allelic control, and multiplexing capability. The approach enables more accessible, cost-effective, and reproducible development, validation, and quality assurance of clinical NGS tests for HCM, with future work aiming to expand the repertoire to cover additional indels and higher multiplexing."
62,"S. Flynn, A. Haenel, F. Coughlan, S. Crilly, J. A. Leipsic, and J. D. Dodd, ""Cardiac CT, MRI, and PET in 2023: Exploration of Key Articles across Imaging and Multidisciplinary Journals,"" Radiology, vol. 313, no. 3, e240975, Dec. 2024. doi: 10.1148/radiol.240975. [Online]. Available: https://pubmed.ncbi.nlm.nih.gov/39688488/","In this review, the authors evaluate recent progress in noninvasive cardiac imaging modalities, concentrating on cardiac CT, MRI, and PET, with an emphasis on significant publications from 2023. They discuss the expanding use of photon-counting CT for coronary and structural assessments, delve into the clinical significance of plaque and functional evaluations, and analyze radiation exposure based on SCOT-HEART trial data. The review highlights advancements in artificial intelligence integration within cardiac imaging, presenting three-year follow-up data from the ADVANCE Registry that demonstrate AI's potential to enhance diagnostic accuracy and cardiovascular patient outcomes. Cardiac MRI studies on various cardiomyopathies and the improved prognostic value of MRI compared to PET in cardiac sarcoidosis are also covered. Additionally, the emerging understanding of the brain-heart axis among radiologists is discussed, and the review summarizes key society statements and guidelines from 2023 relevant to cardiac imaging, outlining contemporary trends and innovative approaches in noninvasive imaging."
63,"M. B. Lawson, W. Zhu, D. L. Miglioretti, T. Onega, L. M. Henderson, G. H. Rauscher, K. Kerlikowske, B. L. Sprague, E. J. A. Bowles, E. S. O'Meara, A. N. A. Tosteson, R. M. diFlorio-Alexander, R. A. Hubbard, J. M. Lee, and C. I. Lee, ""Disparities in Standard-of-Care, Advanced, and Same-Day Diagnostic Services among Patients with Abnormal Screening Mammography,"" Radiology, vol. 314, no. 2, e241673, Feb. 2025. doi: 10.1148/radiol.241673. [Online]. Available: https://pubmed.ncbi.nlm.nih.gov/39964269/","This retrospective study examined over 1.1 million female patients (ages 40-89) across 136 U.S. facilities who underwent more than 3.5 million screening mammograms from 2010 to 2020, aiming to uncover multilevel factors influencing the on-site availability and receipt of diagnostic imaging and biopsy following abnormal screening mammography. Although fully adjusted models revealed that race, ethnicity, and neighborhood-level socioeconomic status generally did not affect on-site diagnostic service availability, significant disparities in care were evident: compared to White patients, minority patients were considerably less likely to receive same-day diagnostic servicesAsian (RR = 0.74; 95% CI: 0.640.85), Black (RR = 0.56; 95% CI: 0.490.63), and Hispanic (RR = 0.61; 95% CI: 0.520.71)and Black patients in particular were less likely to receive same-day biopsies following abnormal results (RR = 0.46; 95% CI: 0.330.65). In summary, while access to on-site diagnostic resources did not differ by demographic variables, actual receipt of timely diagnostic follow-up was lower among racial and ethnic minority groups, highlighting persistent disparities in breast cancer care delivery."
64,"C. Lauri, A. Signore, A.W.J.M. Glaudemans, G. Treglia, O. Gheysens, R.H.J.A. Slart, R. Iezzi, N.H.J. Prakken, E.S. Debus, S. Honig, A. Lejay, N. Chakfé, ""Evidence-based guideline of the European Association of Nuclear Medicine (EANM) on imaging infection in vascular grafts,"" European Journal of Nuclear Medicine and Molecular Imaging, vol. 49, pp. 3430–3451, 2022. https://doi.org/10.1007/s00259-022-05769-x","This guideline, developed by a multidisciplinary working group, offers evidence-based recommendations for the imaging diagnosis of vascular graft/endograft infection (VGEI), a complication with significant morbidity and mortality. After systematic literature review and consensus scoring, the recommendations clarify that computed tomography angiography (CTA) remains the first-line imaging modality due to accessibility and established practice, but has limited sensitivity for low-grade infection, particularly in the early post-surgical phase. Nuclear medicine modalities, particularly radiolabelled white blood cell (WBC) scintigraphy and [18F]FDG PET/CT, provide high diagnostic accuracy for differentiating infection from sterile inflammation, with PET/CT recommended only after at least four months post-surgery to reduce false positives. MRI is not advised as a primary modality given its lower accuracy. The guidelines emphasize individualized, multidisciplinary decision-making, especially regarding imaging in the context of ongoing antibiotic therapy. Challenges highlighted include a lack of head-to-head comparative studies across modalities, heterogenous patient populations, and the need for standardization in protocols and interpretation. Future research should focus on direct intra-patient modality comparison, protocol harmonization, and advanced imaging development. Ultimately, tailored, multidisciplinary approaches to imaging are advocated to optimize patient management and outcomes in suspected VGEI."
65,"F. Fraioli, N. Albert, R. Boellaard, I. Boscolo Galazzo, M. Brendel, I. Buvat, M. Castellaro, D. Cecchin, P. Aguiar Fernandez, E. Guedj, A. Hammers, Z. Kaplar, S. Morbelli, L. Papp, K. Shi, N. Tolboom, T. Traub-Weidinger, A. Verger, D. Van Weehaeghe, I. Yakushev, H. Barthel, ""Perspectives of the European Association of Nuclear Medicine on the role of artificial intelligence (AI) in molecular brain imaging,"" European Journal of Nuclear Medicine and Molecular Imaging, vol. 51, pp. 1007–1011, 2024. https://doi.org/10.1007/s00259-023-06553-1","This paper discusses the evolving role of AI in nuclear neuroimaging, emphasizing the potential for AI-driven advances in clinical and research brain imaging. The introduction outlines the advantages of brain imaging for AI development, such as easier image co-registration and larger accessible datasets, but highlights challenges like data standardization, annotation requirements, and the need for large multi-center datasets. Methods and results sections are not applicable, as this is a review/editorial. The discussion details how AIespecially deep learninghas been leveraged to improve image acquisition (e.g., ToF estimation, noise reduction, attenuation correction, and motion correction using generative adversarial networks). In post-processing, AI enhances segmentation accuracy, registration of images across modalities or timepoints, and extraction of quantitative biomarkers (e.g., amyloid PET quantification without MRI/CT), and potentially enables non-invasive arterial input function estimation. The paper also addresses AI interpretability, advocating for supervision by clinical experts and the development of explainable AI techniques such as saliency maps and feature visualization to ensure robust, trustworthy models. Clinical applications span epilepsy (e.g., focus localization, diagnosis, prognosis), neurodegenerative and movement disorders (assisting differential diagnosis, feature selection), neuro-oncology (tumor segmentation, radiomics), and psychiatric disorders (diagnosis and treatment response prediction). Key challenges include data harmonization, annotation, validation, and high costs, with future work centering on multi-modal integration, improved generalization, systematic validation, and a paradigm shift in psychiatric neuroimaging toward precision medicine."
66,"O. Westerland, A. Amlani, C. Kelly-Morland, M. Fraczek, K. Bailey, M. Gleeson, I. El-Najjar, M. Streetly, P. Bassett, G. J. R. Cook, V. Goh, on behalf of the Myeloma Imaging Research Group at Guy’s & St Thomas’ Hospital, London and King’s College London, ""Comparison of the diagnostic performance and impact on management of 18F-FDG PET/CT and whole-body MRI in multiple myeloma,"" European Journal of Nuclear Medicine and Molecular Imaging, vol. 48, pp. 2558–2565, 2021. https://doi.org/10.1007/s00259-020-05182-2","This study retrospectively compared the diagnostic performance and impact on management of $^{18}$F-fluorodeoxyglucose positron emission tomography/computed tomography ($^{18}$F-FDG PET/CT) and whole-body MRI (WBMRI) in 46 patients with newly diagnosed myeloma who underwent both imaging modalities prior to treatment. WBMRI demonstrated superior per-patient sensitivity for myeloma bone disease (91.3%) compared to $^{18}$F-FDG PET/CT (69.6%), with the PET component alone only achieving 54.3% sensitivity. Concordance between modalities for disease positivity and lesion count occurred in 59% of patients, and in 41.3% WBMRI detected more focal lesions. Interobserver agreement was moderate for $^{18}$F-FDG PET/CT ($\kappa = 0.44-0.47$), and excellent for WBMRI ($\kappa = 1.00$, ICC for lesion scoring = 0.95). Management decisions were also influenced: while clinical data alone would have led to treatment in 69.6% of cases, this increased to 87.0% with addition of $^{18}$F-FDG PET/CT and 93.5% with WBMRI ($p=0.02$ and $p=0.002$ vs. clinical data, respectively), though the difference between the two imaging modalities was not statistically significant ($p=0.08$). Limitations included the study's retrospective design and small sample size. The findings suggest that although WBMRI is more sensitive, either imaging modality appropriately informs initial myeloma management depending on local resources, and further prospective researchespecially into hybrid PET/MRI techniquesis warranted."
67,"Chengdong Shi, Kai Yu, Yu Hu, Yuantao Wang, Fan Bu, Ji Lu, Weigang Wang, ""Diagnostic Efficacy of Various Imaging Modalities Across Different Stages of Prostate Cancer: A Network Meta-Analysis of Diagnostic Studies,"" medRxiv, 2024, Preprint, doi: https://doi.org/10.1101/2024.09.28.24314285. [Direct URL: https://www.medrxiv.org/content/10.1101/2024.09.28.24314285v1]","This network meta-analysis evaluated the diagnostic performance of various imaging modalitiesincluding mpMRI, PSMA PET/CT, MRE, MRSI, BS, CT, PET, and other tracersfor detecting and monitoring prostate cancer at different disease stages, utilizing sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and detection rates from 123 studies comprising 9,371 patients. The results indicated that $^{68}\mathrm{Ga}$-P16-093 PET/CT and $^{68}\mathrm{Ga}$-PSMA-617 PET/CT provided high diagnostic accuracy in early-phase prostate cancer, while $^{68}\mathrm{Ga}$-PSMA-11 PET/MRI was most sensitive for detecting lymph node metastasis. Furthermore, $^{18}\mathrm{F}$-DCFPyL PET/CT had the highest specificity and PPV, whereas $^{18}\mathrm{F}$-PSMA-1007 PET/CT achieved the highest NPV. In bone metastasis detection, $^{18}\mathrm{F}$-PSMA-1007 PET/MRI led in sensitivity and NPV, with $^{18}\mathrm{F}$-Fluciclovine PET/CT excelling in specificity and PPV. For identifying biochemical recurrence, $^{18}\mathrm{F}$-PSMA-1007 PET/CT demonstrated the highest lesion detection rate, and among radiotracers, $^{18}\mathrm{F}$-PSMA-1007 had the best detection rate overall. These findings clarify the relative strengths and limitations of various advanced imaging modalities in the diagnosis and staging of prostate cancer."
68,"Camille Mazzara, Pietro Sorrentino, Irene Altuna, Roma Maghsoudlou, Fabio Ferrarelli, Diego Sona, Luca Cocchi, Alessandro Gozzi, Carlo Miniussi, Silvia De Santis, Francesca Pistoia, Kenji Kansaku, Pau Erola, Gregoire Danaila, Carlo Cavedini, Barry A. Giesbrecht, Gordon Sajda, Rodolphe Jenatton, Emmanuel Daucé, ""Mapping brain lesions to conduction delays: the next step for personalized brain models in Multiple Sclerosis,"" medRxiv, 2024, Preprint, doi: https://doi.org/10.1101/2024.07.10.24310150. [Direct URL: https://www.medrxiv.org/content/10.1101/2024.07.10.24310150v1]","Multiple sclerosis (MS) is a heterogeneous autoimmune disorder marked by myelin sheath damage, leading to slowed nerve conduction linked directly to demyelination severity. This study used large-scale brain models and Bayesian model inversion to relate myelin lesion intensity to conduction delays in white matter tracts, with data from 38 subjects (20 healthy, 18 with MS) who underwent MEG and MRI with tractography. MS patients exhibited lower alpha band (813 Hz) power, and lesion matrices quantified tract-specific damage for each individual. Neural regions were modeled as Stuart-Landau oscillators with subject-specific coupling, and a linear relation, parameterized by $\gamma$, was proposed for translating lesion load into conduction delays, affecting power spectral features. Deep neural density estimators revealed that estimated $\gamma$ correlated strongly (and inversely) with MEG alpha peak frequencies, a relationship not explained by total lesion volume; these parameters also predicted clinical disability across individuals. The findings highlight how location-specific myelin lesions impact conduction delays and spectral profiles, paving the way for individualized modeling of MS pathology."
69,"M. Antillon, M. McFarland, J. Ndung'u, E. Sutherland, M.E. Chappuis, S. Snijders, A. Hope, W.J. de Vlas, E.M. Castaño, ""Cost-effectiveness of sleeping sickness elimination campaigns in the Democratic Republic of Congo: a transmission model-based economic evaluation,"" medRxiv, 2020, Preprint, doi: https://doi.org/10.1101/2020.08.25.20181982. [Direct URL: https://www.medrxiv.org/content/10.1101/2020.08.25.20181982v2]","Gambiense human African trypanosomiasis (gHAT), although greatly reduced in prevalence, remains a challenge in several low-income countries such as the Democratic Republic of Congo (DRC), where elimination of transmission (EOT) by 2030 is the global goal. This study coupled dynamic transmission modeling (using an SEIRS-type variant) with health economic analyses to evaluate the cost-effectiveness of four elimination strategiescombinations of active screening (AS) at regular or intensified coverages, with or without vector control (VC), alongside passive screening (PS)across five DRC health zones spanning varying disease risk. The model assumed cessation of intensified interventions after three years of zero detected cases, with reactivation if cases re-emerge. Results indicate that in moderate and high-risk zones, adding VC is critical for timely EOT, often being cost-saving or highly cost-effective (e.g., in high-risk Kwamouth, VC reduces costs per DALY averted to $4); in contrast, in low-risk areas, minimum-cost strategies involving only AS and PS suffice for high-probability EOT. The bulk (7580%) of expenditures are front-loaded before 2030, with AS and VC as the primary cost drivers except in low-risk settings where PS dominates. Sensitivity analyses demonstrated robustness of cost-effectiveness to uncertainties in coverage, VC efficacy, discounting, and time horizon. Challenges include sustainability of interventions as cases wane, surveillance needs, operational constraints for VC, and future integration of novel treatments/diagnostics. Ultimately, the study supports targeted VC scale-up in higher-risk areaswhere gains are greatest and cost-justifiedwhile affirming that local elimination across diverse settings in DRC is achievable with optimized current approaches."
70,"A. Holzinger, G. Langs, H. Denk, K. Zatloukal, and H. Müller, ""Information fusion as an integrative cross-cutting enabler to achieve robust, explainable, and trustworthy medical artificial intelligence,"" Information Fusion, vol. 79, pp. 263–278, Nov. 2022. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S1566253521002050","Medical artificial intelligence (AI) systems have shown remarkable success, often surpassing human performance and holding great promise to transform healthcare. However, achieving robust, trustworthy, and explainable AI in practical clinical environments requires more than just performance improvements; AI must handle imprecise, missing, and erroneous data, and provide transparent explanations to medical experts regarding both results and the reasoning process. The integration of conceptual knowledge can aid in the development of less biased, more data-efficient models. The paper identifies three critical Frontier Research Areas necessary for this goal: Complex Networks and their Inference, Graph causal models and counterfactuals, and Verification and Explainability methods. It argues that comprehensive information fusion can unify these areas, bridging research and real-world applications for future trustworthy medical AI. Additionally, the inclusion of ethical and legal considerations is emphasized as essential for developing solutions that are both ethically responsible and legally compliant."
71,"Y. Himeur, A. Ghanem, F. Alsalemi, R. Alhameed, F. Bensaali, and A. Amira, ""Data fusion strategies for energy efficiency in buildings: Overview, taxonomy, and future research directions,"" Information Fusion, vol. 64, pp. 99–120, Oct. 2020. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S1566253520303158","This paper addresses the growing importance of data fusion (DF) strategies in enhancing energy efficiency within buildings, which represent a significant proportion of global energy consumption and greenhouse gas emissions. By synthesizing heterogeneous data from sensors, smart meters, and IoT devices, DF can provide comprehensive and actionable insights for optimizing energy usage. The authors provide a thorough survey and taxonomy of existing data fusion mechanismsincluding levels, techniques, influencing factors, incentives, recorded data, platform architectures, IoT technologies, and control algorithmsapplied to building energy management. They conduct a comparative analysis of state-of-the-art frameworks and introduce a novel appliance identification approach based on the fusion of 2D local texture descriptors, where 1D power signals are mapped into 2D space, achieving up to 99.68% accuracy and 99.52% F1 score on three real datasets. The work concludes by discussing open research challenges and proposing future research directions for data fusion-driven, sustainable energy ecosystems in the built environment."
72,"A. Diez-Olivan, J. Del Ser, D. Galar, and B. Sierra, ""Data fusion and machine learning for industrial prognosis: Trends and perspectives towards Industry 4.0,"" Information Fusion, vol. 50, pp. 92–111, Jan. 2019. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S1566253518304706","The emergence of Industry 4.0, marking the smartization of manufacturing through advanced Information and Communication Technologies, enables extraction of valuable insights from industrial assets via intelligent monitoring, data fusion, and machine learning techniques. Data science plays a strategic role in forecasting abnormal equipment behaviors to preempt failures, mitigate risks, and minimize economic and safety impacts. The paper surveys state-of-the-art developments in data fusion and machine learning applied to industrial prognosis, categorizing feature extraction and learning methods by their purposedescriptive (analyzing causes of failure), predictive (estimating time-to-failure), and prescriptive (recommending actions to minimize impact). This tripartite analysis, including hardware and software considerations, provides a foundation and reference for future research and practical applications in industrial prognosis."
73,"P. Dutta, ""An uncertainty measure and fusion rule for conflict evidences of big data via Dempster–Shafer theory,"" International Journal of Image and Data Fusion, vol. 9, no. 2, pp. 187-201, 2018. [Online]. Available: https://www.tandfonline.com/doi/full/10.1080/19479832.2017.1391336","DempsterShafer theory of evidence is a key method for modeling uncertainty, and this paper proposes a novel approach to quantify uncertainty present in big data using this theory. The authors introduce a fusion rule tailored for managing conflicts arising from evidences within big data, aiming to derive a comprehensive global uncertainty measure. The developed theoretical framework and methods, including an evidence conflict fusion rule, are demonstrated with numerical examples to illustrate their effectiveness."
74,"R. Ahmadirouhani, M. H. Karimpour, B. Rahimi, A. Malekzadeh-Shafaroudi, A. Beiranvand Pour, and B. Pradhan, ""Integration of SPOT-5 and ASTER satellite data for structural tracing and hydrothermal alteration mineral mapping: implications for Cu–Au prospecting,"" International Journal of Image and Data Fusion, vol. 9, no. 3, pp. 239-253, 2018. [Online]. Available: https://www.tandfonline.com/doi/full/10.1080/19479832.2018.1469548","Integration of SPOT-5 and ASTER satellite data offers a cost-effective and accurate method for mapping hydrothermal alteration minerals and structural features critical for CuAu prospecting, with SPOT-5 providing high spatial resolution for structural tracing and ASTER excelling in mineral discrimination through its spectral range. The research, conducted in a well-known mineralized belt, utilized SPOT-5 data processed via principal component analysis and edge-detection to extract lineaments, while ASTER bands underwent band ratioing and MNF transforms to distinguish alteration minerals such as iron oxides, clays, and silica. Co-registration and GIS overlay of these datasets facilitated the creation of detailed maps, with fracture analysis linking lineament features to alteration zones. Results revealed that high lineament density regions, derived from SPOT-5, correspond well with ASTER-identified argillic, phyllic, and propylitic alterations, illustrating the structural control on mineral distribution. Intersections of major faults and alteration halos were highlighted as key targets for further CuAu exploration, underscoring the effectiveness of this integrated remote sensing approach."
75,"S. Iino, R. Ito, K. Doi, T. Imaizumi, S. Hikosaka, and T. Y. Saito, ""CNN-based generation of high-accuracy urban distribution maps utilising SAR satellite imagery for short-term change monitoring,"" International Journal of Image and Data Fusion, vol. 9, no. 4, pp. 298-312, 2018. [Online]. Available: https://www.tandfonline.com/doi/full/10.1080/19479832.2018.1491897","This study addresses the challenge of short-term urban change monitoring in rapidly developing countries through the creation of high-accuracy urban distribution maps using SAR satellite imagery processed via a Convolutional Neural Network (CNN). Improvements in dataset construction, including optimized SAR polarization combinations and the integration of Digital Surface Model (DSM) data, enhanced land cover classification accuracy and reduced noise pollution. The methodology produced high-quality urban distribution maps capable of detecting short-term changes by differencing time series SAR images, with results validated against optical satellite data. The approach leverages multisource SAR data (X-, L-, and C-bands) to increase observation opportunities, with further multi-band analysis planned as future work. Overall, the study demonstrates that combining CNN with advanced SAR and DSM data delivers effective solutions for frequent, accurate urban monitoring."
76,"R. J. Appleton, B. C. Barnes, and A. Strachan, “Data Fusion of Deep Learned Molecular Embeddings for Property Prediction,” arXiv preprint arXiv:2504.07297 [cs.LG], Apr. 2025. [Online]. Available: https://arxiv.org/abs/2504.07297","Data-driven methods like deep learning are powerful for predicting material properties but struggle with sparse datasets, limiting their usefulness. While multi-task learning can help by leveraging shared information across related tasks, its effectiveness depends on how correlated the tasks are and how complete the data is. Standard multi-task models often perform poorly when data is both sparse and weakly correlated. To address this, the authors introduce a data fusion approach that combines molecular embeddings from various single-task models, then uses these embeddings to train a multi-task model. Tested on a quantum chemistry benchmark and a newly compiled experimental dataset, this fused approach outperforms standard multi-task models on sparse datasets and yields better predictions for data-limited properties compared to single-task models."
77,"W. Feng, Q. Li, C. Wang, and J.-s. Fan, “Data Fusion for Full-Range Response Reconstruction via Diffusion Models,” arXiv preprint arXiv:2502.00795 [cs.CE], Feb. 2025. [Online]. Available: https://arxiv.org/abs/2502.00795","This paper addresses the challenge in structural health monitoring (SHM) of reconstructing full-range structural responses from sparse and heterogeneous sensor data, a common limitation due to cost and accessibility factors. The authors propose a novel data fusion framework that leverages diffusion models and incorporates Diffusion Posterior Sampling (DPS) guided by probabilistic constraints from sensor measurements, using a lightweight neural network surrogate as the forward model to map full-range responses to local outputs. Their approach demonstrates flexibility for varied sensor configurations, efficient computation, and high accuracy, with experiments on a nonlinear steel plate shear wall system reporting weighted mean absolute percentage error (WMAPE) as low as $1.57\%$ for the neural network model and maintaining WMAPE below $15\%$ even in sparse or noisy measurement scenarios. These results highlight the method's adaptability and robustness, opening new opportunities for probabilistic data fusion and decision-making in SHM applications."
78,"Q. Zhang, Y. Wei, Z. Han, H. Fu, X. Peng, C. Deng, Q. Hu, C. Xu, J. Wen, D. Hu, and C. Zhang, “Multimodal Fusion on Low-quality Data: A Comprehensive Survey,” arXiv preprint arXiv:2404.18947 [cs.LG], Nov. 2024. [Online]. Available: https://arxiv.org/abs/2404.18947","Multimodal fusion aims to integrate information from multiple data modalities to achieve more accurate predictions, benefiting applications like autonomous driving and medical diagnosis. Despite recent progress, little is known about the reliability of such fusion methods under low-quality data conditions. This paper surveys challenges and recent advances in multimodal fusion encountered in real-world scenarios, offering a comprehensive taxonomy from a data-centric perspective. Four primary challenges are identified: (1) noisy multimodal data contaminated by heterogeneous noise, (2) incomplete multimodal data with missing modalities, (3) imbalanced multimodal data where modalities have significantly different quality, and (4) quality-varying multimodal data where modality quality changes dynamically across samples. This taxonomy helps researchers comprehend the current landscape and suggests promising research directions, with a discussion of open problems and future opportunities in the field."
79,"A. Dehghani Zahedani, T. McLaughlin, A. Veluvali, N. Aghaeepour, A. Hosseinian, S. Agarwal, J. Ruan, S. Tripathi, M. Woodward, N. Hashemi, and M. Snyder, ""Digital health application integrating wearable data and behavioral patterns improves metabolic health,"" npj Digital Medicine, vol. 6, Article no. 216, 2023. [Online]. Available: https://www.nature.com/articles/s41746-023-00956-y","This study evaluated the effectiveness of a digital, app-based intervention (the ""Season of Me"" program), integrating continuous glucose monitoring (CGM), physical activity tracking, and AI-driven personalized recommendations to promote lifestyle changes in 2,217 adults spanning normoglycemic, prediabetic, and type 2 diabetic (T2D) status. Over 28 days, with optional follow-up to 12 weeks, users logged food intake, physical activity, and body weight, receiving daily insights such as macronutrient breakdowns, glycemic index (GI), glycemic load (GL), and recommendations based on machine learning models (RNN/LSTM) leveraging CGM, dietary, and wearable data. Significant improvements were observed: among those with T2D and baseline time-in-range (TIR) <90%, TIR increased by 9.8%, mean estimated HbA1c (GMI) fell by 0.43% when baseline GMI >7%, and both hyper- and hypoglycemic events declined. Weight loss occurred in 75.5% of participants tracking weight over 28 dayswith average 12-week losses of 4.4 lbs overall and up to 9.4 lbs for T2D. Physical activity and healthy dietary patterns (increased protein and fiber per calorie, reduced carbohydrate ratio) improved, especially in nondiabetic and prediabetic users. The technology was scalable, app-driven, and did not rely on human coaching, suggesting high potential for broad, cost-efficient deployment to address rising diabetes incidence. However, the study was limited by lack of a control group, short monitoring duration, possible user selection bias, and incomplete demographic/cultural data, warranting longer-term, more diverse future research. Overall, integrated digital interventions with real-time CGM feedback and personalization can enhance metabolic health and support T2D prevention and management at scale."
80,"H. Lee, H.-L. Yang, H. G. Ryu, C.-W. Jung, Y. J. Cho, S. B. Yoon, H.-K. Yoon, and H.-C. Lee, ""Real-time machine learning model to predict in-hospital cardiac arrest using heart rate variability in ICU,"" npj Digital Medicine, vol. 6, Article no. 215, 2023. [Online]. Available: https://www.nature.com/articles/s41746-023-00960-2","This study developed and validated a real-time machine learning model for predicting in-hospital cardiac arrest in ICU patients using only ECG-derived heart rate variability (HRV) parameters. Data from 5,679 ICU stays (event rate 1.88%) were processed from a large single-center registry, with HRV metrics computed in 5-minute ECG epochs up to 24 hours before a cardiac arrest event. A LightGBM (LGBM) model trained on 33 selected HRV features (out of 74 initially computed) achieved an AUROC of 0.881 (95% CI: 0.8750.887) and an AUPRC of 0.104 (0.0930.116) on the validation cohort, outperforming a comparative clinical parameter model (AUROC 0.735, $p < 0.001$). Key predictive features identified by SHAP analysis were the baseline width of the triangular interpolation of the RR interval histogram (TINN), HTI, IALS, Prc20NN, MinNN, and IQRNN; for example, lower TINN and higher IALS were associated with increased arrest risk. Feature trajectories indicated significant HRV measure changes up to 6 hours prior to arrest. While the model enables robust, continuous risk monitoring using universally available ECG data and demonstrates strong generalizability for rare event prediction, it cannot pinpoint the event timing, is limited by its single-center retrospective dataset, and does not dynamically incorporate treatment effects. The code is available at https://github.com/HyeonhoonLee/hrvarrest, but data access is restricted. The authors recommend further validation in larger, multicenter cohorts and investigating integration of additional clinical variables and time-to-event modeling."
81,"M. Nikolova-Simons, R. Keldermann, Y. Peters, W. Compagner, L. Montenij, Y. de Jong, and R. A. Bouwman, ""Predictive analytics for cardio-thoracic surgery duration as a stepstone towards data-driven capacity management,"" npj Digital Medicine, vol. 6, Article no. 205, 2023. [Online]. Available: https://www.nature.com/articles/s41746-023-00938-0","Effective management of operating room (OR) capacity is crucial to avoid surgery cancellations, long waiting lists, and negative outcomes for patients and staff. Traditionally, surgery duration is estimated using the surgeon's average time for the last 10 cases of a given procedure, but discrepancies between planned and actual durations often result in suboptimal schedules and inefficient OR utilization. In a retrospective study of 2294 cardio-thoracic surgeries, new predictive modelsincluding linear regression, random forest, and extreme gradient boostingwere developed using patient and surgery features such as ASA score, number and type of procedures, post-OR bed type, medications, and creatinine levels. These machine learning models, particularly ensemble methods, significantly reduced root mean squared error (RMSE) for elective surgeries by 19% (from 0.99 to 0.80, $p=0.002$) and for acute surgeries by 52% (from 1.87 to 0.89, $p<0.001$), and also decreased the proportion of surgeries ""behind schedule"" by up to 28%. The models outperformed both manual corrections and the traditional mean-based approach, highlighting the importance of using a diverse set of features available at scheduling without requiring intraoperative data. These AI-based tools offer practical, data-driven support to optimize OR utilization and capacity management, emphasizing the value of integrating machine learning into hospital operations for both elective and acute surgery planning."
82,"W. Barker, W. Chang, J. Everson, M. Gabriel, V. Patel, C. Richwine, and C. Strawley, ""The Evolution of Health Information Technology for Enhanced Patient-Centric Care in the United States: Data-Driven Descriptive Study,"" Journal of Medical Internet Research, vol. 26, 2024, Article e59791. Published: Oct. 28, 2024. Available: https://www.jmir.org/2024/1/e59791 doi: 10.2196/59791","Health information technology (health IT) adoption in the United States has surged over the past two decades, primarily due to federal initiatives such as the HITECH Act and the 21st Century Cures Act, resulting in a 10-fold increase in electronic health record (EHR) usage among hospitals and a 5-fold increase among physicians. By 2023, 70% of hospitals were interoperable in all major data exchange domains, while nearly all pharmacies and 92% of prescribers had e-prescribing capabilitiesan 85 percentage point rise since 2008. Patient access to online medical records has also dramatically improved, with 97% of hospitals and 65% of physicians enabling such access. Federal incentives have expanded the digitization and interoperability of clinical care data exchange, e-prescribing, public health reporting, and patient engagement; for example, hospitals enabled electronic reporting for immunizations, lab results, and syndromic surveillance rose from about 60% in 2012 to over 85% in 2022. However, significant challenges remain, including interoperability obstacles, data non-standardization, technical complexity, resource disparities, usability and security issues, and inequitable patient accessespecially for smaller or rural providers. The paper emphasizes the need for continued collaboration, data standardization, transparent algorithms, API enhancements, and governance to address these barriers and achieve a fully integrated, patient-centric health care system. The next era should prioritize infrastructure improvements that allow seamless and secure data flow, bridge digital divides, and support personalized, equitable health care outcomes across the nation."
83,"I. J. Borges do Nascimento, M. S. Marcolino, H. M. Abdulazeem, I. Weerasekara, N. Azzopardi-Muscat, M. A. Gonçalves, and D. Novillo-Ortiz, ""Impact of Big Data Analytics on People’s Health: Overview of Systematic Reviews and Recommendations for Future Studies,"" Journal of Medical Internet Research, vol. 23, no. 4, pp. e27275, Apr. 2021. Available: https://www.jmir.org/2021/4/e27275/ doi: 10.2196/27275","This overview evaluated systematic reviews on the effects of big data analytics in healthcare, focusing on WHOs core health indicators and priorities, notably for noncommunicable diseases and COVID-19. From more than 5,000,000 patients across 35 systematic reviews, big data analytics demonstrated moderate to high accuracy for diagnosing and predicting complications in diabetes mellitus, classifying mental disorders, forecasting suicide attempts, and informing chronic disease management, with studies often using patient data from electronic health records and hospital systems. However, confidence in findings was limited: 25 reviews were rated critically low, 7 low, and only 3 moderate in methodological quality by AMSTAR 2. Methodological challenges included fragmented, unstandardized, and poorly integrated data, lack of reporting protocol transparency and evaluation metrics, insufficient clinical outcome reporting, and workforce skill deficits. Opportunities include supporting real-time analysis, personalized care, disease prediction, epidemic monitoring, cost reduction, and fraud detection, while persistent challenges involve data structure, security, interoperability, regulatory, managerial, and cost concerns. The study calls for robust methodological/reporting standards (including cross-validation, clear evaluation metrics, transparent hyperparameter tuning, and open data/code), standardization, and demonstration of practical impact in future research. In summary, while big data analytics holds promise for improving diagnostic and predictive capacity in several medical domains, realizing its full benefits in public health requires overcoming substantial evidence quality, data governance, and implementation barriers."
84,"M. Wang, S. Li, T. Zheng, N. Li, Q. Shi, X. Zhuo, R. Ding, and Y. Huang, ""Big Data Health Care Platform With Multisource Heterogeneous Data Integration and Massive High-Dimensional Data Governance for Large Hospitals: Design, Development, and Application,"" JMIR Medical Informatics, vol. 10, no. 4, pp. e36481, Apr. 2022. Available: https://medinform.jmir.org/2022/4/e36481/ doi: 10.2196/36481","This paper describes the development and implementation of a hospital-wide big data platform at West China Hospital of Sichuan University (WCH-BDP) to address challenges in integrating, storing, calculating, governing, and securing heterogeneous medical data. Initiated in 2017 and formally launched in 2020, WCH-BDP integrates data from 27 different systemsincluding clinical, laboratory, radiology, management, and appointment dataaccumulating over 12.49 million patient records, 75.67 million visits, and 8475 data variables, with a computing cluster of 252 physical servers and over 20 PB storage. The platform employs a masterslave mode for real-time data integration, separate storage and calculation environments depending on data modality, and advanced governance models that include metadata management, terminology standardization, natural language processing, and a 5S security system (data, app, use, management, ownership). A significant shift from manual to automated self-service data retrieval occurred, cutting average retrieval time from 4.5 to 0.15 hours and increasing monthly retrievals from 166 (manual) to 8561 (self-service). The platform underpins more than 20 major research projects and supports AI applications with high accuracy (e.g., pulmonary nodule detection at 98.8%). WCH-BDP excels over comparable platforms by integrating all business system data continuously and in real timeincluding clinical and hospital management datawhile providing supercomputing resources and a robust analysis environment. Challenges addressed include data structurization, standardization, privacy, security, and computational scalability, with future plans for multicenter data sharing and further analytics. The WCH-BDP demonstrates high application value by enabling effective use of electronic medical records, supporting clinical care, research, and operations management, and paving the way for advanced AI and data-driven healthcare innovations in China."
85,"S. Mohammed, T.-H. Kim, R.-S. Chang, and C. Ramos, ""Guest Editorial: Data Analytics for Public Health Care,"" IEEE Journal of Biomedical and Health Informatics, vol. 26, no. 4, pp. 1409-1410, Apr. 2022. [Online]. Available: https://ieeexplore.ieee.org/document/9757035/","Data analytics can assist population health management in improving patient outcomes, enhancing care management, and addressing social determinants of health."
86,"M. Habib, Z. Wang, S. Qiu, H. Liu, J. Qi, P. Kumar, and W. Chen, ""Machine Learning Based Healthcare System for Investigating the Association Between Depression and Quality of Life,"" IEEE Journal of Biomedical and Health Informatics, vol. 26, no. 6, pp. 2795-2805, Jun. 2022. [Online]. Available: https://ieeexplore.ieee.org/document/9670709/","Future advancements in healthcare are being shaped by technological innovations, particularly in addressing depression, which is recognized as a growing local health risk. This study explores the relationship between depression and various aspects of quality of life using machine learning (ML) techniques for analyzing and administering relevant data. The research is structured in two experimental phases: the first introduces a data consolidation strategy employing the Secure Hash Algorithm (SHA-1) to uniquely identify and organize data links, enhancing the accuracy of information retrieval. In the second phase, a novel model combining supervised and unsupervised ML methods is developed, leveraging the consolidation approach as the basis for research concept formation and validation. Request issues are autonomously managed and structured, resulting in eight distinct classification schemes to further validate the effectiveness of a posterior probability multi-class Support Vector Machine. The creation of depression-inducing factors considers the implications of sample assumptions, and the proposed hybrid ML model demonstrates an improved classification performance with an accuracy rate of 91.16\% as shown in the findings."
87,"G. Dharmarathne, T. N. Jayasinghe, M. Bogahawaththa, D. Meddage, and U. Rathnayake, ""A novel machine learning approach for diagnosing diabetes with a self-explainable interface,"" Healthcare Analytics, vol. 7, Article 100301, 2024. [Online]. Available: https://doi.org/10.1016/j.health.2024.100301","This study presents the first self-explanatory interface for diagnosing diabetes patients using machine learning. The authors developed and compared four classifiersDecision Tree (DT), K-nearest Neighbor (KNN), Support Vector Classification (SVC), and Extreme Gradient Boosting (XGB)on a public diabetes dataset, achieving strong diagnostic accuracy, with XGB outperforming the others. To enhance interpretability, the study employed Shapley Additive Explanations (SHAP), offering granular insights into XGBs prediction logic. The resulting diagnostic interface integrates XGB and SHAP to deliver both accurate diabetes predictions and transparent, case-specific explanations, empowering users to better understand their health status. The paper highlights the importance of interpretable AI in healthcare and suggests that future enhancements with richer clinical data could further assist medical professionals in decision-making."
88,"Kavyashree C., H. S. Vimala, and Shreyas J., ""A systematic review of artificial intelligence techniques for oral cancer detection,"" Healthcare Analytics, vol. 7, Article 100304, Jan. 2024. [Online]. Available: https://doi.org/10.1016/j.health.2024.100304","Oral cancer develops in the tissues of the oral cavity, and early detection is vital to reduce mortality rates. Artificial intelligence (AI) techniques, encompassing deep learning, machine learning, fuzzy computing, data mining, and genetic algorithms, play an increasingly important role in automating and improving the accuracy of oral cancer detection. This study provides an overview of various input image types used for diagnosis, the processing steps such as segmentation and feature extraction, and compares AI approaches with conventional strategies. According to the reviewed literature, deep learning methods are most prevalent (37%), followed by machine learning (32%), genetic algorithms (12%), data mining (10%), and fuzzy computing (9%) in oral cancer detection, each offering specific benefits and drawbacks for clinical application."
89,"R. A. Rasul, P. K. Saha, D. Bala, S. Karim, Md. I. Abdullah, and B. P. Saha, ""An evaluation of machine learning approaches for early diagnosis of autism spectrum disorder,"" Healthcare Analytics, vol. 7, Article 100293, Jun. 2024. [Online]. Available: https://doi.org/10.1016/j.health.2024.100293","The early diagnosis of Autism Spectrum Disorder (ASD) is important for enabling timely intervention and improved outcomes. With traditional ASD diagnosis relying on subjective, time-consuming behavioral assessments, this study systematically evaluates various machine learning (ML) algorithmsincluding Support Vector Machines, Random Forests, XGBoost, k-Nearest Neighbors, Logistic Regression, and deep neural networksacross three public datasets: UCI ASD Screening Adult, UCI ASD Screening Children, and NDAR. The datasets comprise demographic (age, sex), behavioral (AQ-10), and medical history features. Data preprocessing involved imputation for missing values, categorical encoding, normalization, and several feature selection approaches (recursive elimination, univariate tests, domain knowledge). To address class imbalance, methods such as SMOTE were used. ML models were optimized via grid search and cross-validation, with evaluation based on accuracy, precision, recall, F1-score, and area under the ROC curve (AUC). The study aims to highlight the relative strengths and limitations of each model, culminating in practical recommendations for real-world, clinical deployment of ML-based ASD diagnostic tools."
90,"M. Badawy, N. Ramadan, and H. A. Hefny, “Healthcare predictive analytics using machine learning and deep learning techniques: a survey,” Journal of Electrical Systems and Information Technology, vol. 10, Article No. 40, 2023. [Online]. Available: https://jesit.springeropen.com/articles/10.1186/s43067-023-00108-y","This paper provides a comprehensive survey of machine learning (ML) and deep learning (DL) approaches for healthcare prediction, highlighting their critical role in analyzing complex health data for disease diagnosis and prognosis. The authors systematically reviewed 41 articles published between 2019 and 2022, focusing on the application of ML and DL in predicting diseases such as diabetes, COVID-19, heart disease, liver disease, and chronic kidney disease. Their results, summarized in Table 6, show diagnostic accuracies ranging from 75% for liver disease (via logistic regression) up to 98.5% for COVID-19 and multi-disease prediction, emphasizing that model performance varies widely depending on disease type, methodology, and dataset quality. The survey also identifies significant challenges, including processing massive and heterogeneous streaming biomedical data, computational complexity, handling missing data, and the difficulty of generalizing models with limited datasets. The paper concludes that ML and DL possess transformative potential for healthcare analytics by enabling more accurate and timely predictions, but effective deployment in real-world settings requires advances in data integration, innovative algorithms, and solutions to data quality and scalability issues, thus pointing to directions for future research in healthcare predictive analytics. Key abbreviations and methods discussed include AI, ML, DL, SVM, CNNs, LSTM, and others, with detailed definitions provided for terms and algorithms relevant to the field."
91,"M. Giuffrè et al., “Harnessing the power of synthetic data in healthcare,” npj Digital Medicine, vol. 6, Article No. 198, 2023. [Online]. Available: https://www.nature.com/articles/s41746-023-00927-3 (Direct link via medRxiv DOI: https://www.medrxiv.org/lookup/external-ref?access_num=10.1038/s41746-023-00927-3&link_type=DOI)","Data-driven decision-making is central to healthcare innovation, and while synthetic data has succeeded in finance, clinical adoption is hampered by higher stakes, practitioner distrust, and regulatory concerns. This paper reviews synthetic data's applications in healthcare, such as government policy modeling, privacy enhancement, and augmentation for predictive analytics, and foresees its integration in digital twins for personalized medicine. Methods include GANs, VAEs, agent-based simulation, and NLP-driven synthetic data, with applications demonstrated for policy simulation, EHR privacy preservation, COVID-19 imaging, and operational modeling. Key challenges involve data bias, interpretability, auditing difficulties, and privacy risks including re-identification, where standard regulations (HIPAA, GDPR) are insufficient. Although Differential Privacy ($DP$) methodse.g., PATE-GANoffer robust mathematical protection, their implementation is complex and not widespread. The authors propose a digital chain-of-custody framework, incorporating encryption, regulated access, and potentially blockchain, to secure data integrity and enable accountability. Addressing definitional ambiguities, bias mitigation, and regulatory gaps is critical, and the paper calls for collaborative efforts among healthcare professionals, regulators, technologists, and patients to establish guidelines and best practices. In sum, while synthetic data promises transformative advances in healthcare research and efficiency, realizing its benefits responsibly requires overcoming technical, ethical, and regulatory hurdles and ensuring privacy and integrity throughout the data lifecycle."
92,"N. Mehta, Z. Pandit, and S. Shukla, “Transforming healthcare with big data analytics and artificial intelligence: A systematic mapping study,” Journal of Biomedical Informatics, vol. 100, Article 103311, 2019. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S1532046419302235 (Direct link via medRxiv DOI: https://www.medrxiv.org/lookup/external-ref?access_num=10.1016/J.JBI.2019.103311&link_type=DOI)",Assessing the available literature on big data analytics and artificial intelligence in healthcare will help understand the needs in application of these technologies in healthcare by identifying the areas that require additional research and will provide the researchers and industry experts with a base for future work.
93,"Lotfi Madaoui, Abbes Amira, Malika Kedir Talha, Oussama Kerdjidj, Yassine Himeur, ""Image encoding and wearable sensors-based locomotion mode recognition using convolutional recurrent neural networks"", Biomedical Signal Processing and Control, vol. 87, 2025, Art. no. 107068. [Online]. Available: https://doi.org/10.1016/j.bspc.2024.107068",We developed a locomotion mode recognition (LMR) framework implementing Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) with image ...
94,"Xiaoxiao Li, Liye Mei, Mengping Long, Jin Huang, Wei Yang, Xin Hao, Yi-qang Liu, Jinxuan Hou, Yu Xu, Fuling Zhou, Dupei Wang, Jianghua Wu, Taobo Hu, Cheng Lei, ""Accurately matching serial whole slide images for tumor heterogeneity analysis"", Biomedical Signal Processing and Control, vol. 87, 2025, Art. no. 106825. [Online]. Available: https://doi.org/10.1016/j.bspc.2024.106825","This study presents an automated method for matching multi-stained serial whole slide images (WSIs), addressing the challenge of accurately locating common regions in large, heterogeneous image datasets, which is essential for intratumor heterogeneity quantification and personalized cancer treatment. Utilizing the proposed multiscale-ringencoder, three Giga-pixel serial WSIs stained with Hematoxylin-eosin (H&E) and two immunohistochemical (IHC) stains are registered within 9.36 minutes, achieving a spatial uncertainty of less than $200\,\mu\mathrm{m}$; region correspondence among WSIs can be located in just $0.68$ seconds, offering a speed improvement of over $30\times$ compared to manual pathologist work. This precise matching enables whole-slide quantification of markers like Ki-67 in breast cancer, optimizing assessments of tumor heterogeneity and supporting more accurate and personalized diagnosis and treatment, while significantly reducing pathologist workload. The method's code and software are available at https://github.com/WHU-lab/MTH."
95,"T. Schäck, M. Muma, M. Feng, C. Guan, and A. M. Zoubir, ""Robust Nonlinear Causality Analysis of Nonstationary Multivariate Physiological Time Series,"" IEEE Transactions on Biomedical Engineering, vol. 65, no. 6, pp. 1213–1225, Jun. 2018. [Online]. Available: https://ieeexplore.ieee.org/document/7934390","This paper introduces a robust time-varying generalized partial directed coherence (rTV-gPDC) method to enhance causality analysis in biomedical signal processing, particularly for multivariate physiological time series that are nonlinear, nonstationary, and prone to artifacts or outliers. Traditional linear MVAR-based causality measures, such as Granger causality and partial directed coherence (PDC), are limited by their assumptions of linearity and stationarity. The proposed approach employs a polynomial expansion of the MVAR model to capture nonlinear interactions, and estimates its time-varying coefficients using a robust, time-adaptive iteratively reweighted least squares (IRLS) algorithm, which reduces sensitivity to contaminated data. Simulations and applications to real cardiovascular and respiratory time series (from head-up tilt table tests) show rTV-gPDC more accurately reconstructs dynamic, frequency-specific causal relationships, even under nonideal conditions. While rTV-gPDC improves inference fidelity and reveals physiologically meaningful regulatory mechanisms, challenges remain in model order selection, computational cost, and empirical validation due to limited ground truth. The method lays groundwork for future research in automated modelling, extension to more complex networks, and clinical real-time causality analysis, with the ultimate aim of better understanding and monitoring physiological interactions in health and disease."
96,"T. Nguyen-Ky, H. D. Tuan, A. V. Savkin, M. N. Do, and N. T. T. Van, ""Real-Time EEG Signal Classification for Monitoring and Predicting the Transition Between Different Anaesthetic States,"" IEEE Transactions on Biomedical Engineering, vol. 68, no. 5, pp. 1450–1458, May 2021. [Online]. Available: https://ieeexplore.ieee.org/document/9329155/","Quantitative identification of transitions between anaesthetic states is crucial for patient safety during surgery but remains a challenging task because current monitors do not provide clear indicators and clinicians must rely on personal experience. This paper introduces a real-time method that utilizes the Hurst method for pre-processing de-noised electroencephalograph (EEG) signals. The maximum of Hurst's ranges is used as the real-time EEG response and incorporated as a new feature under a moving average framework. The maximum power spectral density of this feature significantly distinguishes different anaesthetic state transitions, making it a robust quantitative index for their identification."
97,"O. W. Samuel, Y. Z. Kulwa, G. Li, R. N. Khushaba, and S. S. Ge, ""Multiresolution Dual-Polynomial Decomposition Approach for Optimized Characterization of Motor Intent in Myoelectric Control Systems,"" IEEE Transactions on Biomedical Engineering, vol. 69, no. 10, pp. 3122–3133, Oct. 2022. [Online]. Available: https://ieeexplore.ieee.org/document/9947222/","Surface electromyogram (sEMG) signals are widely used in biomedical applications, particularly in the control of multifunctional prostheses due to their rich motor content and non-invasive nature; however, their non-linear, non-uniform properties and susceptibility to interference make signal processing challenging. This work proposes a multiresolution decomposition driven by dual-polynomial interpolation (MRDPI) technique for denoising and reconstruction of multi-class EMG signals, aiming to both enhance signal quality and preserve motor information. The optimal MRDPI configuration was determined using combinations of thresholding schemes and resolution levels on EMG datasets from amputees performing up to 22 upper-limb motions, including public NinaPro data. Experimental results indicated that MRDPI-processed signals led to significantly improved and consistent decoding performance across features, classifiers, and datasets, compared to existing methods, supporting its use in practical, intuitive EMG-based control schemes for prosthetics and rehabilitation robots."
98,"Ijaz Ahmad, Zhenzhen Liu, Lin Li, Inam Ullah, Sunday Timothy Aboyeji, Xin Wang, Oluwarotimi W. Samuel, Guanglin Li, Yuan Tao, Yan Chen, and Shixiong Chen, ""Robust Epileptic Seizure Detection Based on Biomedical Signals Using an Advanced Multi-View Deep Feature Learning Approach,"" IEEE Journal of Biomedical and Health Informatics, vol. 28, no. 10, pp. To appear, Oct. 2024. [Online]. Available: https://ieeexplore.ieee.org/document/10517529","Epilepsy is monitored through EEG signals, where accurate epileptic seizure detection depends on precisely identifying EEG features. This study introduces the Advanced Multi-View Deep Feature Learning (AMV-DFL) framework, employing machine learning to enhance EEG feature detection for seizure identification. The approach extracts traditional frequency domain features using fast Fourier transform (FFT) and incorporates time domain features from raw EEG, forming a comprehensive multi-view feature set. Deep features are then autonomously extracted via optimal layers from one-dimensional convolutional neural networks (1D CNN), integrating both domains into multi-view deep features. Classification is performed by a multi-view forest (MV-F), a rule-based, interpretable machine learning classifier, with explainability provided by tree-based SHAP (T-XAI). Experimentally, the AMV-DFL framework outperforms models using only traditional or single-view deep features by 4% and other state-of-the-art methods by an average of 3% in accuracy, thereby aiding clinicians in identifying EEG features relevant to epileptic seizures and potentially discovering novel biomarkers."
99,"P. Ivaturi, D. Chen, T. M. Talbert, Z. Jiang, W. Xu, G. Quer, M. Gadaleta, D. Jha, J. C. Lin, S. Santini, and P. Bonato, ""A Comprehensive Explanation Framework for Biomedical Time Series Classification,"" IEEE Journal of Biomedical and Health Informatics, vol. 25, no. 7, pp. 2398-2408, Jul. 2021. [Online]. Available: https://ieeexplore.ieee.org/document/9360451","This paper introduces a post-hoc explainability framework tailored to deep learning models for quasi-periodic biomedical time-series, with atrial fibrillation (AF) detection from electrocardiogram (ECG) data as the primary use case due to its significant clinical relevance. Utilizing a state-of-the-art pretrained model, the authors develop both global and local explanation strategies: global explanations reveal which segments of repetitive input patternssuch as those associated with R-R interval regularity and the absence of a P-wavedrive classification decisions, aligning well with clinician expectations; local explanations employ analyses like LIME and saliency maps to dissect specific model outcomes and pinpoint critical segments influencing correct or incorrect predictions. Their methodology encompasses comprehensive signal processing, segmentation, normalization, and significance assessment via ablation and permutation studies, demonstrating that essential ECG features substantially affect deep learning decision making. Results show their explanations are interpretable by clinical experts, suggesting pathways to both network improvement and increased transparency essential for clinician trust. The discussion notes the challenge of translating model insights to physiological relevance, and the conclusion states the framework advances understanding and enables refinement of deep learning models for biomedical data, as well as advocating for prospective clinical validation to further establish effectiveness."
100,"A. Song, L. Xu, L. Wang, B. Wang, X. Yang, B. Xu, B. Yang, and S. E. Greenwald, ""Automatic coronary artery segmentation of CCTA images with an efficient feature-fusion-and-rectification 3D-UNet,"" IEEE Journal of Biomedical and Health Informatics, vol. 26, no. 8, pp. 4044-4055, Aug. 2022. [Online]. Available: https://ieeexplore.ieee.org/document/9405480","Automatic coronary artery segmentation is crucial for diagnosing coronary disease; this paper proposes an automated method for coronary CT angiography (CCTA) images using a deep convolutional neural network. The approach involves three main steps: (1) a 2D DenseNet classification network filters out non-coronary slices for efficiency, (2) a segmentation network based on 3D-UNetenhanced with dense blocks in encoding to extract rich features and 3D residual blocks in decoding for feature rectificationperforms accurate vessel segmentation, and (3) a Gaussian weighting process highlights reliable central segmentations while downweighting block boundaries when merging overlapping data. The method achieves a Dice Similarity Coefficient (DSC) of $0.826$ on their constructed CCTA dataset; code is available at https://github.com/alongsong/3D_CAS."
101,"Min-Seo Song and Seung-Bo Lee, ""Comparative study of time-frequency transformation methods for ECG signal classification,"" Frontiers in Signal Processing, vol. 4, Art. no. 1322334, Jan. 2024. [Online]. Available: https://doi.org/10.3389/frsip.2024.1322334","This study addresses the need for automated electrocardiogram (ECG) classification by leveraging convolutional neural networks (CNNs) with a focus on converting 1D ECG signals into 2D images suitable for 2D-CNN input using time-frequency methods such as continuous wavelet transform (CWT) and short-time Fourier transform (STFT). Using the MIT-BIH Arrhythmia Database, ECG segments were transformed into images (notably with the Ricker wavelet), and multiple pre-trained CNN architecturesincluding AlexNet, ResNet-18/152, and DenseNet-121/201were fine-tuned for classifying normal and premature ventricular contraction (PVC) beats. Fine-tuning with transfer learning enhanced CNN performance, with Ricker + ResNet-18 achieving a top accuracy of $96.17\%$. CWT-based transformations generally surpassed STFT in classification accuracy, though STFT was faster ($135.36$ ms/segment vs. $216.36$ ms/segment). Grad-CAM visualizations indicated superior localization of abnormal beats with CWT. The paper highlights the importance of hyperparameter selection in transformation methods, preference for CWT (especially Ricker wavelet), and effectiveness of pre-trained networks with fine-tuning. Limitations involve binary classification, reliance on a single dataset, and generic models, but future work is proposed for multiclass tasks, refined visualizations, custom CNN designs, and broader datasets. Overall, this work offers practical insights for improving ECG interpretation accuracy and efficiency, with direct applications for clinicians, wearable monitors, and real-time cardiac monitoring systems."
102,"Ali K. Ibrahim, Hanqi Zhuang, Emmanuelle Tognoli, Ali Muhamed Ali, and Nurgun Erdol, ""Epileptic seizure prediction based on multiresolution convolutional neural networks,"" Frontiers in Signal Processing, vol. 2, Art. no. 1175305, May 2023. [Online]. Available: https://doi.org/10.3389/frsip.2023.1175305","This work presents an innovative seizure prediction system for epileptic patients using EEG data, leveraging maximal overlap discrete wavelet transform (MODWT) to decompose EEG signals into frequency bands (delta, theta, alpha, beta, gamma), with a multiresolution 1D convolutional neural network (CNN) extracting features from each band. The architecture aggregates the CNN outputs to classify 10-s frames, combining 30 consecutive frames to determine preictal (pre-seizure) or interictal states in a 5-min sliding window, optimizing sensitivity and minimizing false prediction rates (FPR). Evaluated on the CHB-MIT (scalp EEG) and Kaggle/American Epilepsy Society (intracranial EEG) datasets, the model achieved an average sensitivity of 82% and FPR of 0.058 on CHB-MIT, and 85% sensitivity with a 0.19 FPR on the Kaggle dataset, outperforming prior methods (see Table below). The approach is patient-specific, requires no handcrafted features, and is generalizable across datasets. Challenges include dataset imbalance, patient variability, optimal threshold setting, and limited interpretability of CNN features by channel or frequency. The authors propose future work in improving interpretability and artifact handling. The method, by automating feature extraction and delivering accurate, personalized warnings, has strong potential for real-world deployment and improved quality of life for patients in resource-limited settings.

\[
\begin{tabular}{lcc}
\hline
Dataset & Sensitivity (\%) & FPR \\
\hline
CHB-MIT & 82 & 0.058 \\
Kaggle & 85 & 0.19 \\
State-of-art (CHB-MIT, 13 pts) & 90.2 & 0.0713 \\
\hline
\end{tabular}
\]"
103,"Christos Chatzichristos, Lauren Swinnen, Jaiver Macea, Miguel Bhagubai, Wim Van Paesschen, and Maarten De Vos, ""Multimodal detection of typical absence seizures in home environment with wearable electrodes,"" Frontiers in Signal Processing, vol. 2, Art. no. 1014700, Oct. 2022. [Online]. Available: https://doi.org/10.3389/frsip.2022.1014700","This study introduces a novel multimodal pipeline for automated absence seizure detection using wearable EEG devices equipped with integrated inertial measurement unit (IMU) sensors, evaluated for the first time in a phase-4, multicenter, at-home clinical trial. Involving patients with Juvenile Absence Epilepsy, the researchers developed and tested a robust algorithm combining EEG and movement data (accelerometer, gyroscope), balancing the highly imbalanced seizure detection problem via cluster-based under-sampling and implementing new methods to remove movement artifacts and poor-quality data segments prevalent in home recordings. Features were extracted from overlapping 2-second windows for classification using a weighted SVM with RBF kernel. Multi-source training (including data from other patients' home recordings) further improved detection when individual training data were limited. Results from both individual and cross-patient home evaluations showed high sensitivity and substantial reductions in false alarms per hour, outperforming previous approaches and even identifying seizures missed by expert neurologists. Key findings are summarized in terms of sensitivity and false alarms per hour ($\mathrm{FAs/h}$), and the pipelines multimodal postprocessing (using IMU data) was essential for artifact rejection. The study concludes that automated, wearable-based seizure detection is feasible and reliable in real-world environments, with future work aiming for broader validation, improved artifact handling, and exploration of deep learning methods as larger datasets become available."
104,"P. Hu, Z. Huang, D. Peng, X. Wang, and X. Peng, ""Cross-modal retrieval with partially mismatched pairs,"" IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 45, no. 8, pp. 9595-9610, 2023. [Online]. Available: https://ieeexplore.ieee.org/document/10050111/","In this paper, the authors address the problem of partially mismatched pairs (PMPs) in cross-modal retrieval, where noise from incorrectly matched multimedia data (like images and captions) from sources such as the Conceptual Captions dataset can significantly degrade retrieval performance. To handle this, they propose a unified Robust Cross-modal Learning (RCL) framework, which employs an unbiased estimator of cross-modal retrieval risk and a novel complementary contrastive learning paradigm. Their approach focuses on negative pair information (less likely to be noisy), avoiding overfitting to incorrectly labeled positive pairs, while leveraging all available negatives to counteract potential underfitting from weak supervision. Additionally, the method introduces the minimization of risk upper bounds to concentrate on hard samples for further performance gains. The effectiveness and robustness of RCL are validated through extensive experiments across five benchmark datasets and against nine state-of-the-art methods for image-text and video-text retrieval tasks. The code is publicly released at https://github.com/penghu-cs/RCL."
105,"F. Ma, C. Liu, C. Aggarwal, J. Gao, and J. Han, ""Self-paced Multi-view Co-training,"" Journal of Machine Learning Research, vol. 21, no. 182, pp. 1-31, 2020. [Online]. Available: https://www.jmlr.org/papers/volume21/18-794/18-794.pdf","Co-training is a widely used semi-supervised learning method where classifiers on different data views exchange pseudo labels of unlabeled samples iteratively; however, early stages often introduce falsely labeled instances that are not eliminated from training, and classical methods mainly focus on two-view cases with unintuitive multi-view extensions and lack clear optimization models. To solve these issues, this paper proposes a unified self-paced multi-view co-training (SPamCo) framework that draws unlabeled instances with replacement and introduces two co-regularization terms for selecting pseudo-labeled data, sharing an optimization strategy consistent with classic co-training and easily extendable to multi-view problems. The framework allows distributed optimization, enabling parallel classifier training for each view and enhancing algorithm efficiency. Theoretical analysis shows that the SPamCo algorithm is PAC learnable, ensuring its learning and generalization capabilities. Experiments on synthetic and diverse real-world datasets, including text categorization, person re-identification, image recognition, and object detection, demonstrate the superiority of SPamCo over existing methods."
106,"P. M. Kumar, U. P. Rao, P. Vijayakumar, N. Chilamkurti, D. Q. Phung, and N. Kumaravel, ""Clouds Proportionate Medical Data Stream Analytics for Internet of Things-Based Healthcare Systems,"" IEEE Journal of Biomedical and Health Informatics, vol. 26, no. 3, pp. 973-982, Mar. 2022. [Online]. Available: https://ieeexplore.ieee.org/document/9520255/","Internet of Things (IoT) assisted healthcare systems aim to enable ubiquitous access and recommendations for electronic health services, but their reliability hinges on efficiently managing heterogeneous data streams with varying errors. This paper introduces Proportionate Data Analytics (PDA), a method that processes such streams by differentiating data based on variation and error to better satisfy service responses. Using linear regression, the system segregates errors from variations across recurring time intervals, dynamically classifying and responding to stream anomalies to maintain high service response ratios. The methods performance is evaluated using accuracy, identification ratio, delivery, variation factor, and processing time as key metrics."
107,"S. Indra Priyadharshini, D. Shiny Irene, J. Rene Beulah, N. P. Ponnuviji, ""Enhancing real-time health monitoring with hybrid recurrent long short-term tyrannosaurus search for menstrual cups"", Biomedical Signal Processing and Control, vol. 87, 2025, Art. no. 107065. [Online]. Available: https://doi.org/10.1016/j.bspc.2024.107065",This study proposed the Hybrid Recurrent Long Short-term based Tyrannosaurus Search (HRLS-TS) algorithm for real-time health monitoring during menstruation.
